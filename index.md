# A School for all Seasons on *Trustworthy Machine Learning*

List curated by [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en) (National University of Singapore) and [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en) (University of Toronto and Vector Institute)

Machine learning algorithms are trained on potentially sensitive data, and are increasingly being used in critical decision making processes. Can we trust machine learning frameworks to have access to personal data? Can we trust the models not to reveal personal information or sensitive decision rules? In the settings where training data is noisy or adversarially crafted, can we trust the algorithms to learn robust decision rules? Can we trust them to make correct predictions on adversarial or noisy data? Bias affecting some groups in the population underlying a dataset can arise from both a lack of representation in data but also poor choices of learning algorithms. Can we build trustworthy algorithms that remove disparities and provide fair predictions for all groups? To identify various issues with machine learning algorithms and establish trust, can we provide informative interpretation of machine learning decisions? These are the major questions that the emerging research field of trustworthy machine learning aims to respond.

We have selected different sub-topics and key related research papers (as starting points) to help a student learn about this research area. There are so many good papers which are being published in this domain. This list is by no means comprehensive. Papers are selected here with the intention of maximizing coverage of the techniques introduced in the literature in as few papers as possible. Students are encouraged to dive deeper by reading the follow-up research papers. 

## Privacy and Confidentiality

### Data Inference Attacks

- Background

  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), [Thomas Steinke](https://scholar.google.com.sg/citations?user=kwnwhrgAAAAJ&hl=en), and [Jonathan Ullman](https://scholar.google.com.sg/citations?user=WfS41RAAAAAJ&hl=en). "**Exposed! a survey of attacks on private data**." In Annual Review of Statistics and Its Application, 2017. [[**paper**](https://projects.iq.harvard.edu/files/privacytools/files/pdf_02.pdf)]
  
- [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), Marco Stronati, [Congzheng Song](https://scholar.google.com/citations?user=lkPKfjgAAAAJ&hl=en), and [Vitaly Shmatikov](https://www.cs.cornell.edu/~shmat/). "**Membership inference attacks against machine learning models**." In IEEE Symposium on Security and Privacy (SP), 2017. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2017.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=rDm1n2gceJY)] [[**citations**](https://scholar.google.com.sg/scholar?cites=8935131557155912004&as_sdt=2005&sciodt=0,5&hl=en)]

- [Milad Nasr](https://scholar.google.com/citations?user=k6-nvDAAAAAJ&hl=en), [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Amir Houmansadr](https://scholar.google.com/citations?user=cTTFHNwAAAAJ&hl=en). "**Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning**." In IEEE Symposium on Security and Privacy (SP), 2019. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2019.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=lzJY4BjCxTc)] [[**citations**](https://scholar.google.com.sg/scholar?oi=bibs&hl=en&cites=2009427570736671135,3616975283750298005,4006729549039865027)]

- [Congzheng Song](https://scholar.google.com/citations?user=lkPKfjgAAAAJ&hl=en), and [Ananth Raghunathan](https://scholar.google.com/citations?user=KQNjz6cAAAAJ&hl=en). "**Information Leakage in Embedding Models**." In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, 2020. [[**paper**](https://arxiv.org/pdf/2004.00053)]

#### Memorization 

- [Nicholas Carlini](https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en), Chang Liu, [Úlfar Erlingsson](https://scholar.google.com/citations?user=cX2HlhQAAAAJ&hl=en), Jernej Kos, and [Dawn Song](https://scholar.google.com/citations?user=84WzBlYAAAAJ&hl=en). "**The secret sharer: Evaluating and testing unintended memorization in neural networks**." In USENIX Security Symposium, 2019. [[**paper**](https://www.usenix.org/system/files/sec19-carlini.pdf)]  [[**conference talk**](https://www.youtube.com/watch?v=U9XbFtCWedE)] [[**citations**](https://scholar.google.com/scholar?cites=14719809661253001007&as_sdt=2005&sciodt=0,5&hl=en)]

- [Vitaly Feldman](https://scholar.google.com/citations?user=GqZBmfgAAAAJ&hl=en). "**Does learning require memorization? a short tale about a long tail**." In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, 2020. [[**paper**](https://arxiv.org/pdf/1906.05271)] [[**talk**](https://www.youtube.com/watch?v=Fp7cgHRl8Yc)] [[**follow-up paper**](https://arxiv.org/abs/2008.03703)] [[**citations**](https://scholar.google.com/scholar?cites=17943279247461969250&as_sdt=2005&sciodt=0,5&hl=en)]

### Model Inference Attacks

- [Florian Tramèr](https://scholar.google.com.sg/citations?user=ijH0-a8AAAAJ&hl=en&oi=sra), Fan Zhang, Ari Juels, Michael K. Reiter, and [Thomas Ristenpart](https://scholar.google.com.sg/citations?user=MGVrVSIAAAAJ&hl=en). "**Stealing machine learning models via prediction APIs**." In USENIX Security Symposium, 2016. [[**paper**](https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=qGjzmEzPkiI)] [[**citations**](https://scholar.google.com/scholar?cites=14391097248497422196&as_sdt=2005&sciodt=0,5&hl=en)]

- [Lejla Batina](https://scholar.google.com.sg/citations?user=jsDgMzkAAAAJ&hl=en), Shivam Bhasin, Dirmanto Jap, and Stjepan Picek. "**CSI NN: Reverse Engineering of Neural Network Architectures Through Electromagnetic Side Channel**." In USENIX Security Symposium, 2019. [[**paper**](https://www.usenix.org/system/files/sec19-batina.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=dZbrBILRz_c)]

- [Varun Chandrasekaran](https://scholar.google.com.sg/citations?user=Sl7nSOsAAAAJ&hl=en), [Kamalika Chaudhuri](https://scholar.google.com/citations?user=I-DJ7EsAAAAJ&hl=en), Irene Giacomelli, [Somesh Jha](https://scholar.google.com.sg/citations?user=BaI7l8QAAAAJ&hl=en), and Songbai Yan. "**Exploring Connections Between Active Learning and Model Extraction**." In USENIX Security Symposium, 2020. [[**paper**](https://www.usenix.org/system/files/sec20-chandrasekaran.pdf)] 

- [Matthew Jagielski](https://scholar.google.com.sg/citations?user=_8rw_GMAAAAJ&hl=en), [Nicholas Carlini](https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en), David Berthelot, Alex Kurakin, and [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en). "**High Accuracy and High Fidelity Extraction of Neural Networks**." In USENIX Security Symposium, 2020. [[**paper**](https://www.usenix.org/system/files/sec20-jagielski.pdf)]

### Privacy-Preserving Learning

- Background

  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), [Frank McSherry](https://scholar.google.com/citations?user=YYJ3aycAAAAJ&hl=en), [Kobbi Nissim](https://scholar.google.com/citations?user=U-RE8IgAAAAJ&hl=en), and [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en). "**Calibrating noise to sensitivity in private data analysis**." In Theory of cryptography conference, 2006. [[**paper**](https://iacr.org/archive/tcc2006/38760266/38760266.pdf)] 
  
  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), and [Aaron Roth](https://scholar.google.com/citations?user=kLUQrrYAAAAJ&hl=en). "**The algorithmic foundations of differential privacy**." Foundations and Trends in Theoretical Computer Science 9, 2014. [[**book**](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)]

- [Kamalika Chaudhuri](https://scholar.google.com.sg/citations?user=I-DJ7EsAAAAJ&hl=en), Claire Monteleoni, and [Anand D. Sarwate](https://scholar.google.com.sg/citations?user=jgr1-eEAAAAJ&hl=en). "**Differentially private empirical risk minimization**." In Journal of Machine Learning Research 12, no. 3, 2011. [[**paper**](https://jmlr.csail.mit.edu/papers/volume12/chaudhuri11a/chaudhuri11a.pdf)] [[**tutorial talk at NIPS 2017**](https://vimeo.com/248492174)] [[**citations**](https://scholar.google.com.sg/scholar?cites=3955023019589847494&as_sdt=2005&sciodt=0,5&hl=en)]

- [Raef Bassily](https://scholar.google.com.sg/citations?user=C8qMVQUAAAAJ&hl=en), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), and [Abhradeep Thakurta](https://scholar.google.com.sg/citations?user=1rV69hMAAAAJ&hl=en). "**Private empirical risk minimization: Efficient algorithms and tight error bounds**." In IEEE 55th Annual Symposium on Foundations of Computer Science, 2014. [[**paper**](https://arxiv.org/pdf/1405.7085)] [[**talk by AT at MSR**](https://www.youtube.com/watch?v=djjO2sS3jac)] [[**follow-up paper**](https://robobees.seas.harvard.edu/files/privacytools/files/1405.7085v1.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=10593391545542726017&as_sdt=2005&sciodt=0,5&hl=en)]

- [Martin Abadi](https://scholar.google.com.sg/citations?user=vWTI60AAAAAJ&hl=en), Andy Chu, [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), [Brendan McMahan](https://scholar.google.com.sg/citations?user=iKPWydkAAAAJ&hl=en), [Ilya Mironov](https://scholar.google.com.sg/citations?user=hg3A9TgAAAAJ&hl=en), [Kunal Talwar](https://scholar.google.com.sg/citations?user=XD_01h8AAAAJ&hl=en), and Li Zhang. "**Deep learning with differential privacy**." In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, 2016. [[**paper**](https://arxiv.org/pdf/1607.00133)] [[**conference talk**](https://www.youtube.com/watch?v=ZxDBEyjiPxI)] [[**citations**](https://scholar.google.com.sg/scholar?cites=11431158613977668861&as_sdt=2005&sciodt=0,5&hl=en)]

- [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en), [Martin Abadi](https://scholar.google.com.sg/citations?user=vWTI60AAAAAJ&hl=en), [Úlfar Erlingsson](https://scholar.google.com/citations?user=cX2HlhQAAAAJ&hl=en), [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), and [Kunal Talwar](https://scholar.google.com.sg/citations?user=XD_01h8AAAAJ&hl=en). "**Semi-supervised knowledge transfer for deep learning from private training data**." In Proceedings of the 5th International Conference on Learning Representations, 2017. [[**paper**](https://arxiv.org/pdf/1610.05755)] [[**conference talk**](https://www.youtube.com/watch?v=bDayquwDgjU)] [[**follow-up paper**](https://arxiv.org/pdf/1802.08908)] [[**citations**](https://scholar.google.com.sg/scholar?cites=7453137533162499463&as_sdt=2005&sciodt=0,5&hl=en)]

- [Milad Nasr](https://scholar.google.com/citations?user=k6-nvDAAAAAJ&hl=en), [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Amir Houmansadr](https://scholar.google.com/citations?user=cTTFHNwAAAAJ&hl=en). "**Machine learning with membership privacy using adversarial regularization**." In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, 2018. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-CCS2018.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=53gELTL3ibA)] [[**citations**](https://scholar.google.com.sg/scholar?cites=8366684875630861099&as_sdt=2005&sciodt=0,5&hl=en)]

- Overview Talks

  - [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), "**Differential Privacy**." 2019. [[Tutorial](https://www.youtube.com/watch?v=Xz7k0wIW9nc)]
  
  - [Kunal Talwar](https://scholar.google.com.sg/citations?user=XD_01h8AAAAJ&hl=en), "**Large-Scale Private Learning**." 2019. [[Part I](https://www.youtube.com/watch?v=Cwx4LJutHt8)], [[Part II](https://www.youtube.com/watch?v=HsXJnW0Hi4k)]
  
  - [Ilya Mironov](https://scholar.google.com/citations?user=hg3A9TgAAAAJ&hl=en), "**Rényi Differential Privacy**." 2018. [[Talk](https://www.youtube.com/watch?v=oQzaA5KG3pM)]

### Confidential Computing

- [Payman Mohassel](https://scholar.google.com.sg/citations?user=g2xwfAMAAAAJ&hl=en&oi=sra), and Peter Rindal. "**ABY3: A mixed protocol framework for machine learning**." In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, 2018. [[**paper**](https://eprint.iacr.org/2018/403.pdf)]  [[**conference talk**](https://www.youtube.com/watch?v=X8l8XMNyHDM)] [[**citations**](https://scholar.google.com.sg/scholar?cites=9543562417119487548&as_sdt=2005&sciodt=0,5&hl=en)]

- [Chiraag Juvekar](https://scholar.google.com.sg/citations?user=i0OTdKIAAAAJ&hl=en), [Vinod Vaikuntanathan](https://scholar.google.com.sg/citations?user=a8jIPIkAAAAJ&hl=en), and [Anantha Chandrakasan](https://scholar.google.com.sg/citations?user=N6ah30sAAAAJ). "**GAZELLE: A low latency framework for secure neural network inference**." In 27th USENIX Security Symposium, 2018. [[**paper**](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-juvekar.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=Aw6NScFMKXs)] [[**citations**](https://scholar.google.com.sg/scholar?cites=10196223049020093629&as_sdt=2005&sciodt=0,5&hl=en)]

- [Olga Ohrimenko](https://scholar.google.com/citations?user=lzfVm_8AAAAJ&hl=en), [Felix Schuster](https://scholar.google.de/citations?user=YKAVKXAAAAAJ&hl=en), [Cédric Fournet](https://scholar.google.de/citations?user=I30A7HcAAAAJ&hl=en), Aastha Mehta, Sebastian Nowozin, Kapil Vaswani, and Manuel Costa. "**Oblivious multi-party machine learning on trusted processors**." In 25th USENIX Security Symposium, 2016. [[**paper**](https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_ohrimenko.pdf)] [[**conference talk**](https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/ohrimenko)] [[**citations**](https://scholar.google.com.sg/scholar?cites=14174388165763279983&as_sdt=2005&sciodt=0,5&hl=en)] 

### Machine Unlearning

- [Lucas Bourtoule](https://scholar.google.com.sg/citations?user=Elvl65kAAAAJ&hl=en), [Varun Chandrasekaran](https://scholar.google.com.sg/citations?user=Sl7nSOsAAAAJ&hl=en), Christopher Choquette-Choo, Hengrui Jia, Adelin Travers, Baiwu Zhang, [David Lie](https://scholar.google.com.sg/citations?user=Qm_3B70AAAAJ&hl=en), and [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en). "**Machine unlearning**." arXiv preprint arXiv:1912.03817, 2019. [[**paper**](https://arxiv.org/pdf/1912.03817)]

- [Seth Neel](https://scholar.google.com.sg/citations?user=k4Q3TYwAAAAJ&hl=en), [Aaron Roth](https://scholar.google.com.sg/citations?user=kLUQrrYAAAAJ&hl=en), and [Saeed Sharifi-Malvajerdi](https://scholar.google.com.sg/citations?user=lRhBdecAAAAJ&hl=en). "**Descent-to-Delete: Gradient-Based Methods for Machine Unlearning**." arXiv preprint arXiv:2007.02923, 2020. [[**paper**](https://arxiv.org/pdf/2007.02923)]

### Decentralized (Collaborative, Federated) Learning

- [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Vitaly Shmatikov](https://www.cs.cornell.edu/~shmat/). "**Privacy-preserving deep learning**." In Proceedings of the 22nd ACM SIGSAC conference on computer and communications security, 2015. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-CCS2015.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=13974194320253379739&as_sdt=2005&sciodt=0,5&hl=en)]

- [Brendan McMahan](https://scholar.google.com.sg/citations?user=iKPWydkAAAAJ&hl=en), Eider Moore, [Daniel Ramage](https://scholar.google.com.sg/citations?user=D0NeJxMAAAAJ&hl=en), Seth Hampson, and Blaise Aguera y Arcas. "**Communication-efficient learning of deep networks from decentralized data**." In Artificial Intelligence and Statistics, 2017. [[**paper**](https://arxiv.org/pdf/1602.05629)] [[**citations**](https://scholar.google.com.sg/scholar?oi=bibs&hl=en&cites=121527355242954284&as_sdt=5)]

- [Virginia Smith](https://scholar.google.com.sg/citations?user=bldHpWIAAAAJ&hl=en), [Chao-Kai Chiang](https://scholar.google.com.sg/citations?user=pBQgK_YAAAAJ&hl=en), [Maziar Sanjabi](https://scholar.google.com.sg/citations?user=bc_N2-oAAAAJ&hl=en), and [Ameet S. Talwalkar](https://scholar.google.co.th/citations?user=TW7U1W0AAAAJ&hl=en). "**Federated multi-task learning**." In Advances in Neural Information Processing Systems, 2017. [[**paper**](http://papers.nips.cc/paper/7029-federated-multi-task-learning.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=2729989706953112243&as_sdt=2005&sciodt=0,5&hl=en)]

- [Peter Kairouz](https://scholar.google.com.sg/citations?user=m8NUgw0AAAAJ&hl=en) et al. "**Advances and open problems in federated learning**." arXiv preprint arXiv:1912.04977, 2019. [[**paper**](https://arxiv.org/pdf/1912.04977)]

### Law and Policy

- [Kobbi Nissim](https://scholar.google.com/citations?user=U-RE8IgAAAAJ&hl=en), [Aaron Bembenek](https://scholar.google.com/citations?user=Ql2u7VoAAAAJ&hl=en), [Alexandra Wood](https://cyber.harvard.edu/people/awood), [Mark Bun](https://scholar.google.com/citations?user=oDwLyYUAAAAJ&hl=en), [Marco Gaboardi](https://scholar.google.com/citations?user=5b8D1MgAAAAJ&hl=en), [Urs Gasser](https://cyber.harvard.edu/people/ugasser), [David R. O'Brien](https://cyber.harvard.edu/people/dobrien), [Thomas Steinke](https://scholar.google.com/citations?user=kwnwhrgAAAAJ&hl=en), and [Salil Vadhan](https://scholar.google.com/citations?user=dqVjyRQAAAAJ&hl=en). "**Bridging the gap between computer science and legal approaches to privacy**." Harvard Journal of Law & Technology, Volume 31, 2018. [[**paper**](https://dash.harvard.edu/bitstream/handle/1/37355739/Bridging_the_Gap_between_Computer_Science_and_Legal_Approaches_to_Privacy.pdf)] [[**talk by KN**](https://www.youtube.com/watch?v=4FRbAmXvec8)] [[**citations**](https://scholar.google.com/scholar?cites=12818689832408026903&as_sdt=2005&sciodt=0,5&hl=en)]

### Tools and Libraries

- [Open Differential Privacy](https://github.com/opendifferentialprivacy)

- [TensorFlow Privacy](https://github.com/tensorflow/privacy)

- [TF Encrypted](https://tf-encrypted.io/) [[**talk**](https://www.youtube.com/watch?v=kiB882Gphlc)]

- [ML Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter) [[**talk**](https://www.youtube.com/watch?v=DWqnKNZTz10)]

### Related Courses and Schools

- [Privacy in Statistics and Machine Learning](https://dpcourse.github.io), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en) and [Jonathan Ullman](https://scholar.google.com.sg/citations?user=WfS41RAAAAAJ&hl=en), 2021. 

- [Data Privacy: Foundations and Applications](https://simons.berkeley.edu/programs/privacy2019), Simons Institute for the Theory of Computing, 2019. 

- [Applied Privacy for Data Science](http://people.seas.harvard.edu/~salil/cs208/), [James Honaker](https://scholar.google.com/citations?user=q0WV4cgAAAAJ&hl=en) and [Salil Vadhan](https://scholar.google.com/citations?user=dqVjyRQAAAAJ&hl=en), Harvard, 2019.

- [Privacy in Machine Learning and Statistical Inference](https://docs.google.com/document/d/1jsZLEd3ZM-ZWdNAjNRI4_bgPysRUsKQDHvy4VKgtzJ8/edit), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), Boston University, 2018.

- [The Algorithmic Foundations of Adaptive Data Analysis](https://adaptivedataanalysis.com/), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en) and [Aaron Roth](https://scholar.google.com/citations?user=kLUQrrYAAAAJ&hl=en), UPenn and Boston University, 2017.

- [Algorithms for Private Data Analysis](http://www.gautamkamath.com/CS860-fa2020.html), [Gautam Kamath](https://scholar.google.com/citations?user=MK6zHkYAAAAJ&hl=en), University of Waterloo, 2020.

## Robustness

### Training Phase

- Background

  - [Ilias Diakonikolas](https://scholar.google.com/citations?user=Vb3FLmkAAAAJ&hl=en), and [Daniel M. Kane](https://scholar.google.com/citations?user=DulpV-cAAAAJ&hl=en). "**Recent advances in algorithmic high-dimensional robust statistics**." arXiv preprint arXiv:1911.05911, 2019. [[**paper**](https://arxiv.org/pdf/1911.05911)]
  
  - [Ankur Moitra](https://scholar.google.com/citations?hl=en&user=umFQktIAAAAJ), "**Robustness Meets Algorithms**." 2019. [[**Talk**](https://www.youtube.com/watch?v=qxZQml1897Q)] 

- Battista Biggio, Blaine Nelson, Pavel Laskov. "**Poisoning Attacks against Support Vector Machines**". In International Conference on Machine Learning, 2012. [[**paper**](https://arxiv.org/abs/1206.6389)]

- [Chiyuan Zhang](https://scholar.google.com.sg/citations?user=l_G2vr0AAAAJ&hl=en), [Samy Bengio](https://scholar.google.com.sg/citations?user=Vs-MdPcAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en), [Benjamin Recht](https://scholar.google.com.sg/citations?user=a_dbdxAAAAAJ&hl=en), and [Oriol Vinyals](https://scholar.google.com.sg/citations?user=NkzyCvUAAAAJ&hl=en). "**Understanding deep learning requires rethinking generalization**." In International Conference on Learning Representations, 2017. [[**paper**](https://arxiv.org/pdf/1611.03530)] [[**conference talk**](https://www.youtube.com/watch?v=kCj51pTQPKI)] [[**citations**](https://scholar.google.com.sg/scholar?cites=4613672282544622621&as_sdt=2005&sciodt=0,5&hl=en)]

- [Jacob Steinhardt](https://scholar.google.com/citations?user=LKv32bgAAAAJ&hl=en), [Pang Wei W. Koh](https://scholar.google.com/citations?user=Nn990CkAAAAJ&hl=en), and [Percy S. Liang](https://scholar.google.com/citations?user=pouyVyUAAAAJ&hl=en). "**Certified defenses for data poisoning attacks**." In Advances in neural information processing systems, 2017. [[**paper**](http://papers.nips.cc/paper/6943-certified-defenses-for-data-poisoning-attacks.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=10474944557566613837&as_sdt=2005&sciodt=0,5&hl=en)]

- Matthew Jagielski, Alina Oprea, Battista Biggio, Chang Liu, Cristina Nita-Rotaru, Bo Li. "**Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning**" In IEEE Symposium on Security and Privacy, 2018. [[**paper**](https://arxiv.org/abs/1804.00308)]

- Ilias Diakonikolas, Gautam Kamath, Daniel M. Kane, Jerry Li, Jacob Steinhardt, Alistair Stewart. **Sever: A Robust Meta-Algorithm for Stochastic Optimization**. In ICML 2019. [[**paper**](https://arxiv.org/abs/1803.02815)]

### Inference Phase

#### Integrity

- [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), [Jonathon Shlens](https://scholar.google.com.sg/citations?user=x5bC-UwAAAAJ&hl=en), and [Christian Szegedy](https://scholar.google.com.sg/citations?user=3QeF7mAAAAAJ&hl=en). "**Explaining and harnessing adversarial examples**." International Conference on Learning Representations, 2015. [[**paper**](https://arxiv.org/pdf/1412.6572)] [[**citations**](https://scholar.google.com.sg/scholar?cites=14908107896544813002&as_sdt=2005&sciodt=0,5&hl=en)] [follow-ups: [**universal perturbation**](https://arxiv.org/pdf/1610.08401), [**physical world**](https://arxiv.org/pdf/1707.08945.pdf), [**random steps in iterative adversarial training**](https://arxiv.org/abs/1706.06083), [**attacks on question answering**](https://arxiv.org/abs/1707.07328), [**attacks on audio and semantic segmentation**](https://arxiv.org/pdf/1707.05373.pdf)] 

- Nicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z. Berkay Celik, Ananthram Swami. "**Practical Black-Box Attacks against Machine Learning**". In Asia Conference on Computer and Communications Security, 2017. [[**paper**](https://arxiv.org/abs/1602.02697)] [follow-ups: [**transferability**](https://arxiv.org/pdf/1605.07277), [**gradient-free black-box attacks**](https://dl.acm.org/doi/abs/10.1145/3128572.3140448)]

- [Nicholas Carlini](https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en), and [David Wagner](https://scholar.google.com/citations?user=67kghxAAAAAJ&hl=en). "**Towards evaluating the robustness of neural networks**." In IEEE symposium on security and privacy (SP), 2017. [[**paper**](https://www.ieee-security.org/TC/SP2017/papers/518.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=yIXNL88JBWQ)] [[**citations**](https://scholar.google.com/scholar?cites=6732985638826567603&as_sdt=2005&sciodt=0,5&hl=en)] [follow-ups: [**evading detection**](https://arxiv.org/pdf/1705.07263)]

- [Jeremy Cohen](https://scholar.google.com.sg/citations?user=r493814AAAAJ&hl=en), [Elan Rosenfeld](https://scholar.google.com.sg/citations?user=f0j0K8QAAAAJ&hl=en), and [Zico Kolter](https://scholar.google.com.sg/citations?user=UXh1I6UAAAAJ&hl=en). "**Certified Adversarial Robustness via Randomized Smoothing**." In International Conference on Machine Learning, 2019. [[**paper**](https://arxiv.org/pdf/1902.02918)] [[**talk by ZK**](https://www.youtube.com/watch?v=UHs2mGBH0Fg)] [[**citations**](https://scholar.google.com/scholar?cites=7039519782328477041&as_sdt=2005&sciodt=0,5&hl=en)]

- [Yair Carmon](https://scholar.google.com/citations?user=kTKmpT0AAAAJ&hl=en), [Aditi Raghunathan](https://scholar.google.com/citations?user=Ch9iRwQAAAAJ&hl=en), [Ludwig Schmidt](https://scholar.google.com/citations?user=SWMKy70AAAAJ&hl=en), [John C. Duchi](https://scholar.google.com/citations?user=i5srt20AAAAJ&hl=en), and [Percy S. Liang](https://scholar.google.com/citations?user=pouyVyUAAAAJ&hl=en). "**Unlabeled data improves adversarial robustness**." In Advances in Neural Information Processing Systems, 2019. [[**paper**](https://papers.nips.cc/paper/9298-unlabeled-data-improves-adversarial-robustness.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=5182550296368877701&as_sdt=2005&sciodt=0,5&hl=en)]

- Overview Talks

  - [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), "**Adversarial Examples and Adversarial Training**." 2017. [[Lecture](https://www.youtube.com/watch?v=CIfsB_EYsVI)]
  
  - [Zico Kolter](https://scholar.google.com.sg/citations?user=UXh1I6UAAAAJ&hl=en) and [Aleksander Madry](https://scholar.google.com/citations?user=SupjsEUAAAAJ&hl=en), "**Adversarial Robustness - Theory and Practice**." 2018. [[NeurIPS Tutorial](https://www.youtube.com/watch?v=TwP-gKBQyic)]
  
- Benchmarks

  - Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu. "**Towards Deep Learning Models Resistant to Adversarial Attacks**." In ICLR, 2018. [[**paper**](https://arxiv.org/abs/1706.06083)]
  
#### Availability

- [Sanghyun Hong](https://scholar.google.com/citations?user=664LW90AAAAJ&hl=en), [Pietro Frigo](https://scholar.google.com/citations?user=WJLYoXcAAAAJ&hl=en), [Yiğitcan Kaya](https://scholar.google.com/citations?user=tPiXuV0AAAAJ&hl=en), [Cristiano Giuffrida](https://scholar.google.com/citations?user=2QmtNQsAAAAJ&hl=en), and [Tudor Dumitraș](https://scholar.google.com/citations?user=f6terwoAAAAJ&hl=en). "**Terminal brain damage: Exposing the graceless degradation in deep neural networks under hardware fault attacks**." In USENIX Security Symposium, 2019. [[**paper**](https://www.usenix.org/system/files/sec19-hong.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=o_CY-cFNfRo)]

- Ilia Shumailov, Yiren Zhao, Daniel Bates, Nicolas Papernot, Robert Mullins, Ross Anderson, "**Sponge Examples: Energy-Latency Attacks on Neural Networks**". Preprint, 2020. [[**paper**](https://arxiv.org/abs/2006.03463)]
  
  
### Testing and Verification

- [Guy Katz](https://scholar.google.com/citations?user=3nYG5BMAAAAJ&hl=en), [Clark Barrett](https://scholar.google.com/citations?user=BtwmZfQAAAAJ&hl=en), [David L. Dill](https://scholar.google.com/citations?user=uy8T6BYAAAAJ&hl=en), [Kyle Julian](https://scholar.google.com/citations?user=NlnpI7QAAAAJ&hl=en), and [Mykel J. Kochenderfer](https://scholar.google.com/citations?user=cAy9G6oAAAAJ&hl=en). "**Reluplex: An efficient SMT solver for verifying deep neural networks**." In International Conference on Computer Aided Verification, 2017. [[**paper**](https://arxiv.org/pdf/1610.06940)] [[**conference talk**](https://www.youtube.com/watch?v=KiKS_zaPb64)] [[**citations**](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16898270665626409672)]

- [Gagandeep Singh](https://scholar.google.com/citations?user=m4b2ruEAAAAJ&hl=en), [Timon Gehr](https://scholar.google.com/citations?user=HcL76tsAAAAJ&hl=en), [Markus Püschel](https://scholar.google.com/citations?user=az9ZryAAAAAJ&hl=en), and [Martin Vechev](https://scholar.google.com/citations?user=aZ1Rh50AAAAJ&hl=en). "**An abstract domain for certifying neural networks**." Proceedings of the ACM on Programming Languages (POPL), 2019. [[**paper**](https://files.sri.inf.ethz.ch/website/papers/DeepPoly.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=5Tkc1kgCXRI)] [[**citations**](https://scholar.google.com/scholar?cites=17913918431933235756&as_sdt=2005&sciodt=0,5&hl=en)]

- Xiaowei Huang Marta Kwiatkowska  Sen Wang Min Wu. "**Safety Verification of Deep Neural Networks**". In Computer Aided Verification, 2017. [[**paper**](https://link.springer.com/chapter/10.1007/978-3-319-63387-9_1)]


### Tools and Libraries

- [CleverHans](https://github.com/tensorflow/cleverhans)

- [Foolbox](https://github.com/bethgelab/foolbox)

### Law and Policy

- Ram Shankar Siva Kumar, Jonathon Penney, Bruce Schneier, Kendra Albert. "**Legal Risks of Adversarial Machine Learning Research**" In ICML 2020 Workshop on Law & Machine Learning. [[**paper**](https://arxiv.org/abs/2006.16179)]

### Related Courses and Schools

- [Reliable and Interpretable Artificial Intelligence](https://www.sri.inf.ethz.ch/teaching/riai2020), [Martin Vechev](https://scholar.google.com/citations?user=aZ1Rh50AAAAJ&hl=en), ETH Zurich, 2020.

## Algorithmic Fairness

- Overview

  - [Alexandra Chouldechova](https://scholar.google.com.sg/citations?user=uoDW9hkAAAAJ&hl=en), and [Aaron Roth](https://scholar.google.com.sg/citations?user=kLUQrrYAAAAJ&hl=en). "**The frontiers of fairness in machine learning**." arXiv preprint arXiv:1810.08810, 2018. [[**paper**](https://arxiv.org/pdf/1810.08810)]
  
  - [Solon Barocas](https://scholar.google.com/citations?user=rEjgIskAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), and [Arvind Narayanan](https://scholar.google.com/citations?user=0Bi5CMgAAAAJ&hl=en). "**Fairness and machine learning: Limitations and Opportunities**." Work in progress book, 2019. [[**book**](https://fairmlbook.org/pdf/fairmlbook.pdf)]

- Overview Talks

  - [Solon Barocas](https://scholar.google.com/citations?user=rEjgIskAAAAJ&hl=en) and [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), "**Fairness in machine learning**." [[**Tutorial at NIPS**](https://vimeo.com/248490141)], 2017.
  
  - [Arvind Narayanan](https://scholar.google.com/citations?user=0Bi5CMgAAAAJ&hl=en), "**21 fairness definitions and their politics**." 2018. [[**Tutorial**](https://www.youtube.com/watch?v=jIXIuYdnyyk)]
  
  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), "**The Emerging Theory of Algorithmic Fairness**." 2018. [[**Talk**](https://www.youtube.com/watch?v=g-z84_nRQhw)]
  
  - [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), "**Fairness**." [[**Part I**](https://www.youtube.com/watch?v=Igq_S_7IfOU)], [[**Part II**](https://www.youtube.com/watch?v=9oNVFQ9llPc)]
  
  - [Suresh Venkatasubramanian](https://scholar.google.com.sg/citations?user=Z03FLwkAAAAJ&hl=en), "**Algorithmic Fairness and Unfairness: A New Research Area**." 2019. [[**Talk**](https://www.youtube.com/watch?v=uneZRF6Rm08)] 
  
### Measures 

- [Cynthia Dwork](https://scholar.google.com/citations?user=y2H5xmkAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), Toniann Pitassi, [Omer Reingold](https://scholar.google.com/citations?user=TD9RhcgAAAAJ&hl=en), and [Richard Zemel](https://scholar.google.com/citations?user=iBeDoRAAAAAJ&hl=en). "**Fairness through awareness**." In Proceedings of the 3rd innovations in theoretical computer science conference, 2012. [[**paper**](https://arxiv.org/pdf/1104.3913)] [[**citations**](https://scholar.google.com/scholar?cites=15887350027958465759&as_sdt=2005&sciodt=0,5&hl=en)]

- [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), [Eric Price](https://scholar.google.com/citations?user=UE6z_m8AAAAJ&hl=en), and [Nati Srebro](https://scholar.google.com/citations?user=ZnT-QpMAAAAJ&hl=en). "**Equality of opportunity in supervised learning**." In Advances in neural information processing systems, 2016. [[**paper**](http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=2062984936384963570&as_sdt=2005&sciodt=0,5&hl=en)]

- [Matt J. Kusner](https://scholar.google.com/citations?user=57KRSu8AAAAJ&hl=en), [Joshua Loftus](https://scholar.google.com/citations?user=SIbr3XUAAAAJ&hl=en), [Chris Russell](https://scholar.google.com/citations?user=RM2sHhYAAAAJ&hl=en), and [Ricardo Silva](https://scholar.google.com/citations?user=I-ANa0QAAAAJ&hl=en). "**Counterfactual fairness**." In Advances in neural information processing systems, 2017. [[**paper**](http://papers.nips.cc/paper/6995-counterfactual-fairness.pdf)] [[**talk by MK**](https://www.youtube.com/watch?v=ZfuOw02U7hs)] [[**citations**](https://scholar.google.com/scholar?cites=13115459093902017069&as_sdt=2005&sciodt=0,5&hl=en)]

### Mechanisms

- [Rich Zemel](https://scholar.google.com.sg/citations?user=iBeDoRAAAAAJ&hl=en), [Yu Wu](https://scholar.google.com.sg/citations?user=-eJHVt8AAAAJ&hl=en), [Kevin Swersky](https://scholar.google.com.sg/citations?user=IrixA8MAAAAJ&hl=en), Toni Pitassi, and [Cynthia Dwork](https://scholar.google.com/citations?user=y2H5xmkAAAAJ&hl=en). "**Learning fair representations**." In International Conference on Machine Learning, 2013. [[**paper**](http://www.jmlr.org/proceedings/papers/v28/zemel13.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=6130171396735864663&as_sdt=2005&sciodt=0,5&hl=en)]

- Michael Feldman, [Sorelle A. Friedler](https://scholar.google.com/citations?user=XDHr1VIAAAAJ&hl=en), [John Moeller](https://scholar.google.com/citations?user=AUHBWKIAAAAJ&hl=en), [Carlos Scheidegger](https://scholar.google.com.sg/citations?user=8uHMJjsAAAAJ&hl=en), and [Suresh Venkatasubramanian](https://scholar.google.com.sg/citations?user=Z03FLwkAAAAJ&hl=en). "**Certifying and removing disparate impact**." In proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, 2015. [[**paper**](https://arxiv.org/pdf/1412.3756)] [[**conference talk**](https://www.youtube.com/watch?v=4ds9fBDtMmU)] [[**citations**](https://scholar.google.com.sg/scholar?oi=bibs&hl=en&cites=9404979763053543288&as_sdt=5)]

- [Muhammad Bilal Zafar](https://scholar.google.com.sg/citations?user=keWdp0AAAAAJ&hl=en), [Isabel Valera](https://scholar.google.com.sg/citations?user=cpdQqpsAAAAJ&hl=en), [Manuel Gomez Rogriguez](https://scholar.google.com.sg/citations?user=UcuXmuwAAAAJ&hl=en), and [Krishna P. Gummadi](https://scholar.google.com.sg/citations?user=Bz3APTsAAAAJ&hl=en). "**Fairness constraints: Mechanisms for fair classification**." In Artificial Intelligence and Statistics, 2017. [[**paper**](http://proceedings.mlr.press/v54/zafar17a/zafar17a.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=13152667258933603266&as_sdt=2005&sciodt=0,5&hl=en)]

- [Alekh Agarwal](https://scholar.google.com/citations?user=9nnDvooAAAAJ&hl=en), Alina Beygelzimer, [Miroslav Dudík](https://scholar.google.com/citations?user=wYMTld8AAAAJ&hl=en), [John Langford](https://scholar.google.com/citations?user=LFiqVpwAAAAJ&hl=en), and [Hanna Wallach](https://scholar.google.com/citations?user=OcPVegoAAAAJ&hl=en). "**A reductions approach to fair classification**." In International Conference on Machine Learning, 2018. [[**paper**](https://arxiv.org/pdf/1803.02453)] [[**citations**](https://scholar.google.com/scholar?cites=16870675827052455946&as_sdt=2005&sciodt=0,5&hl=en)]

- B. H. Zhang, B. Lemoine, and M. Mitchell, "**Mitigating Unwanted Biases with Adversarial Learning**." in Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society - AIES ’18 [[**paper**](https://arxiv.org/abs/1801.07593)]

### Analysis

- [Jon Kleinberg](https://scholar.google.com/citations?user=VX7d5EQAAAAJ&hl=en), [Sendhil Mullainathan](https://scholar.google.com/citations?user=oExfyEkAAAAJ&hl=en), and [Manish Raghavan](https://scholar.google.com/citations?user=WaGlwJ4AAAAJ&hl=en). "**Inherent trade-offs in the fair determination of risk scores**." arXiv preprint arXiv:1609.05807, 2016. [[**paper**](https://arxiv.org/pdf/1609.05807)] [[**talk by JK**](https://www.youtube.com/watch?v=K7i_tnflZ64)] [[**citations**](https://scholar.google.com.sg/scholar?cites=17988184943074251625&as_sdt=2005&sciodt=0,5&hl=en)]

- [Sam Corbett-Davies](https://scholar.google.com.sg/citations?user=sKDlVpwAAAAJ&hl=en), [Emma Pierson](https://scholar.google.com.sg/citations?user=xGORWi0AAAAJ&hl=en)], [Avi Feller](https://scholar.google.com.sg/citations?user=Mz7heb4AAAAJ&hl=en), [Sharad Goel](https://scholar.google.com.sg/citations?user=Vv8UdowAAAAJ&hl=en), and Aziz Huq. "**Algorithmic decision making and the cost of fairness**." In Proceedings of the 23rd acm SIGKDD international conference on knowledge discovery and data mining, 2017. [[**paper**](https://arxiv.org/pdf/1701.08230)] [[**talk by SCD**](https://www.youtube.com/watch?v=pm2IVjnnMRY)] [[**citations**](https://scholar.google.com.sg/scholar?cites=2698186144635429170&as_sdt=2005&sciodt=0,5&hl=en)]

- [Lydia T. Liu](https://scholar.google.com.sg/citations?user=IQ2eTA8AAAAJ&hl=en), [Sarah Dean](https://scholar.google.com.sg/citations?user=xhKqjpYAAAAJ&hl=en), [Esther Rolf](https://scholar.google.com.sg/citations?user=n1EE3-8AAAAJ&hl=en), [Max Simchowitz](https://scholar.google.com.sg/citations?user=QhG_7egAAAAJ&hl=en), and [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en). "**Delayed impact of fair machine learning**." In International Conference on Machine Learning, 2018. [[**paper**](http://proceedings.mlr.press/v80/liu18c/liu18c.pdf)] [[**talk by LL**](https://www.youtube.com/watch?v=8cDVtXjvq9s)] [[**citations**](https://scholar.google.com/scholar?client=firefox-b-d&um=1&ie=UTF-8&lr&cites=5181623229195224544)]

- Awad, Edmond, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-François Bonnefon, and Iyad Rahwan. "**The Moral Machine Experiment**". in Nature 2018. [[**paper**](https://www.nature.com/articles/s41586-018-0637-6)]

### Robustness

- [Avrim Blum](https://scholar.google.com.sg/citations?user=Jlv4MR4AAAAJ&hl=en), and [Kevin Stangl](https://scholar.google.com.sg/citations?user=76AAneMAAAAJ&hl=en). "**Recovering from biased data: Can fairness constraints improve accuracy?**." In 1st Symposium on Foundations of Responsible Computing (FORC), 2020. [[**paper**](https://arxiv.org/pdf/1912.01094)]  [[**conference talk**](https://www.youtube.com/watch?v=O0qfqZ7HHuY)]

- [Heinrich Jiang](https://scholar.google.com.sg/citations?user=RiDdF2YAAAAJ&hl=en), and [Ofir Nachum](https://scholar.google.com.sg/citations?user=C-ZlBWMAAAAJ&hl=en). "**Identifying and correcting label bias in machine learning**." In International Conference on Artificial Intelligence and Statistics, 2020. [[**paper**](http://proceedings.mlr.press/v108/jiang20a/jiang20a.pdf)]

- Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, [Ehsan Kazemi](https://scholar.google.com.sg/citations?user=kdyalCwAAAAJ&hl=en), and [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en). "**On Adversarial Bias and the Robustness of Fair Machine Learning**." arXiv preprint arXiv:2006.08669, 2020. [[**paper**](https://arxiv.org/pdf/2006.08669)]

### Related Courses and Schools

- [Recent Developments in Research on Fairness](https://simons.berkeley.edu/workshops/schedule/10758), Simons Institute for the Theory of Computing, 2019.

- [Fairness in Machine Learning](https://fairmlclass.github.io/), [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en), UC Berkeley, 2017.

- [Fairness in Machine Learning](https://docs.google.com/document/d/1XnbJXELA0L3CX41MxySdPsZ-HNECxPtAw4-kZRc7OPI/edit), [Arvind Narayanan](https://scholar.google.com/citations?user=0Bi5CMgAAAAJ&hl=en), Princeton, 2017.

- [Human-Centered Machine Learning](http://courses.mpi-sws.org/hcml-ws18/schedule.html), [Krishna P. Gummadi](https://scholar.google.com.sg/citations?user=Bz3APTsAAAAJ&hl=en), MPI-Software, 2018.

### Tools and libraries

-  [IBM AIF360](https://github.com/Trusted-AI/AIF360)

-  [Microsoft Fairlearn](https://github.com/fairlearn/fairlearn)

## Algorithmic Transparency

- [Finale Doshi-Velez](https://scholar.google.com.sg/citations?user=hwQtFB0AAAAJ&hl=en), and [Been Kim](https://scholar.google.com.sg/citations?user=aGXkhcwAAAAJ&hl=en). "**Towards a rigorous science of interpretable machine learning**." arXiv preprint arXiv:1702.08608, 2017. [[**paper**](https://arxiv.org/pdf/1702.08608)] [[**talk by FDV**](https://www.youtube.com/watch?v=MMxZlr_L6YE)]

- [Brent Mittelstadt](https://scholar.google.com.sg/citations?user=tP685zYAAAAJ&hl=en), [Chris Russell](https://scholar.google.com.sg/citations?user=RM2sHhYAAAAJ&hl=en), and [Sandra Wachter](https://scholar.google.com.sg/citations?user=ZXBJVqYAAAAJ&hl=en). "**Explaining explanations in AI**." In Proceedings of the conference on fairness, accountability, and transparency, 2019. [[**paper**](https://arxiv.org/pdf/1811.01439)]

- Overview talks

  - [Cynthia Rudin](https://scholar.google.com/citations?user=mezKJyoAAAAJ&hl=en). "**Do Simpler Models Exist and How Can We Find Them?**." [[**keynote talk at KDD**](https://www.youtube.com/watch?v=wL4X4lG20sM)]
  
  - [Rich Caruana](https://scholar.google.com/citations?user=B2U8EUwAAAAJ&hl=en). "**Friends Don’t Let Friends Deploy Black-Box Models: Intelligibility in Machine Learning for Bias Detection and Correction**." [[**talk**](https://www.youtube.com/watch?v=TPY16CSIrwY)]

### Model Explanation

- [Sandra Wachter](https://scholar.google.com.sg/citations?user=ZXBJVqYAAAAJ&hl=en), [Brent Mittelstadt](https://scholar.google.com.sg/citations?user=tP685zYAAAAJ&hl=en), and [Chris Russell](https://scholar.google.com.sg/citations?user=RM2sHhYAAAAJ&hl=en). "**Counterfactual explanations without opening the black box: Automated decisions and the GDPR**." Harvard Journal of Law & Technology, 2017. [[**paper**](https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=5948704720199512282&as_sdt=2005&sciodt=0,5&hl=en)]

- [Marco Tulio Ribeiro](https://scholar.google.com.sg/citations?user=rmsIyGMAAAAJ&hl=en), [Sameer Singh](https://scholar.google.com.sg/citations?user=-hGZC54AAAAJ&hl=en), and [Carlos Guestrin](https://scholar.google.com.sg/citations?user=DpLFv4gAAAAJ&hl=en). "**"Why should I trust you?" Explaining the predictions of any classifier**." In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 2016. [[**paper**](https://arxiv.org/pdf/1602.04938)] [[**conference talk**](https://www.youtube.com/watch?v=KP7-JtFMLo4)] [[**talk by SS**](https://www.youtube.com/watch?v=LAm4QmVaf0E)] [[**citations**](https://scholar.google.com.sg/scholar?cites=16724302923321127943&as_sdt=2005&sciodt=0,5&hl=en)] 

- [Scott M. Lundberg](https://scholar.google.com/citations?user=ESRugcEAAAAJ&hl=en), and [Su-In Lee](https://scholar.google.com/citations?user=3ifikJ0AAAAJ&hl=en). "**A unified approach to interpreting model predictions**." In Advances in neural information processing systems, 2017. [[**paper**](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=6828961408019591083&as_sdt=2005&sciodt=0,5&hl=en)]

- [Anupam Datta](https://scholar.google.com/citations?user=oK3QM1wAAAAJ&hl=en), [Shayak Sen](https://scholar.google.com/citations?user=vdiw0xMAAAAJ&hl=en), and [Yair Zick](https://scholar.google.com/citations?user=m0PW6DQAAAAJ&hl=en). "**Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems**." In IEEE symposium on security and privacy (SP), 2016. [[**paper**](https://www.andrew.cmu.edu/user/danupam/datta-sen-zick-oakland16.pdf)] [[**talk by AD**](https://youtu.be/Q6UuncHgUaA?t=1623)] [[**citations**](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14953509643678714899&as_sdt=5)]

### Interpretability

- [Cynthia Rudin](https://scholar.google.com/citations?user=mezKJyoAAAAJ&hl=en). "**Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead**." Nature Machine Intelligence 1, 2019. [[**paper**](https://arxiv.org/pdf/1811.10154)]

### Recourse

- [Berk Ustun](https://scholar.google.com.sg/citations?user=6z_XWYcAAAAJ&hl=en), [Alexander Spangher](https://scholar.google.com.sg/citations?user=pZEaPR8AAAAJ&hl=en), and [Yang Liu](https://scholar.google.com.sg/citations?user=jKrIVCIAAAAJ&hl=en). "**Actionable recourse in linear classification**." In Proceedings of the Conference on Fairness, Accountability, and Transparency, 2019. [[**paper**](https://arxiv.org/pdf/1809.06514)] [[**conference talk**](https://youtu.be/iZM4_YNw4Mw)] [[**citations**](https://scholar.google.com.sg/scholar?cites=9971779227054924463&as_sdt=2005&sciodt=0,5&hl=en)]

### Robustness

- [Julius Adebayo](https://scholar.google.com.sg/citations?user=y1bnRg4AAAAJ&hl=en), [Justin Gilmer](https://scholar.google.com.sg/citations?user=Ml_vQ8MAAAAJ&hl=en), [Michael Muelly](https://scholar.google.com.sg/citations?user=F2SAhnQAAAAJ&hl=en), [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en), and [Been Kim](https://scholar.google.com.sg/citations?user=aGXkhcwAAAAJ&hl=en). "**Sanity checks for saliency maps**." In Advances in Neural Information Processing Systems, 2018. [[**paper**](http://papers.neurips.cc/paper/8160-sanity-checks-for-saliency-maps.pdf)] [[**conference talk**](https://www.facebook.com/nipsfoundation/videos/515859272265612/), starts at 53'] [[**citations**](https://scholar.google.com.sg/scholar?cites=8767887416569707674&as_sdt=2005&sciodt=0,5&hl=en)]

- [Amirata Ghorbani](https://scholar.google.com.sg/citations?user=BtgIFycAAAAJ&hl=en), [Abubakar Abid](https://scholar.google.com.sg/citations?user=8slGl3oAAAAJ&hl=en), and [James Zou](https://scholar.google.com.sg/citations?user=23ZXZvEAAAAJ&hl=en). "**Interpretation of neural networks is fragile**." In Proceedings of the AAAI Conference on Artificial Intelligence, 2019. [[**paper**](https://arxiv.org/pdf/1710.10547)] [[**conference talk**](https://www.youtube.com/watch?v=8KyZCmBTPNw)] [[**citations**](https://scholar.google.com/scholar?cites=8913730552362106675&as_sdt=2005&sciodt=0,5&hl=en)]

- [Dylan Slack](https://scholar.google.com/citations?user=pyhz-gUAAAAJ&hl=en), Sophie Hilgard, Emily Jia, [Sameer Singh](https://scholar.google.com/citations?user=-hGZC54AAAAJ&hl=en), and [Himabindu Lakkaraju](https://scholar.google.com/citations?user=oWid5PQAAAAJ&hl=en). "**Fooling lime and shap: Adversarial attacks on post hoc explanation methods**." In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 2020. [[**paper**](https://arxiv.org/pdf/1911.02508)] [[**talk by HL**](https://www.youtube.com/watch?v=4HyJIOenIlI)] [[**citations**](https://scholar.google.com/scholar?cites=8884301126625541721&as_sdt=2005&sciodt=0,5&hl=en)]

### Privacy and Confidentiality

- [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), [Martin Strobel](https://scholar.google.com/citations?user=6p4Fg_wAAAAJ&hl=en), and [Yair Zick](https://scholar.google.com/citations?user=m0PW6DQAAAAJ&hl=en). "**On the Privacy Risks of Model Explanations**." arXiv preprint arXiv:1907.00164, 2019. [[**paper**](https://arxiv.org/pdf/1907.00164)] [[**citations**](https://scholar.google.com/scholar?cites=1863276377879092856&as_sdt=2005&sciodt=0,5&hl=en)]

- [Neel Patel](https://scholar.google.com/citations?user=zN081ZcAAAAJ&hl=en), [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Yair Zick](https://scholar.google.com/citations?user=m0PW6DQAAAAJ&hl=en). "**Model Explanations with Differential Privacy**." arXiv preprint arXiv:2006.09129, 2020. [[**paper**](https://arxiv.org/pdf/2006.09129)] 

- [Smitha Milli](https://scholar.google.com/citations?user=tsXh_hwAAAAJ&hl=en), [Ludwig Schmidt](https://scholar.google.com/citations?user=SWMKy70AAAAJ&hl=en), [Anca D. Dragan](https://scholar.google.com/citations?user=UgHB5oAAAAAJ&hl=en), and [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en). "**Model reconstruction from model explanations**." In Proceedings of the Conference on Fairness, Accountability, and Transparency, 2019. [[**paper**](https://arxiv.org/pdf/1807.05185)] [[**conference talk**](https://youtu.be/iZM4_YNw4Mw?t=593)] [[**citations**](https://scholar.google.com/scholar?cites=10127227002337427345&as_sdt=2005&sciodt=0,5&hl=en)]

### Analysis 

- [Jon Kleinberg](https://scholar.google.com.sg/citations?user=VX7d5EQAAAAJ&hl=en), and [Sendhil Mullainathan](https://scholar.google.com/citations?user=oExfyEkAAAAJ&hl=en). "**Simplicity creates inequity: implications for fairness, stereotypes, and interpretability**." In Proceedings of the 2019 ACM Conference on Economics and Computation, 2019. [[**paper**](https://arxiv.org/pdf/1809.04578)] [[**conference talk**](https://www.youtube.com/watch?v=LsracoT6zvI)] [[**citations**](https://scholar.google.com/scholar?client=firefox-b-d&um=1&ie=UTF-8&lr&cites=4367467261022093783)]

### Law and Policy

- [Andrew D. Selbst](https://scholar.google.com.sg/citations?user=stza7JMAAAAJ&hl=en), and [Solon Barocas](https://scholar.google.com.sg/citations?user=rEjgIskAAAAJ&hl=en). "**The Intuitive Appeal of Explainable Machines**." Fordham law review 87, no. 3, 2018. [[**paper**](http://fordhamlawreview.org/wp-content/uploads/2018/11/11_Selbst-Barocas-1085-1139-updated-12-4.pdf)] 

### Related Courses and Schools

- [Interpretability and Explainability in Machine Learning](https://interpretable-ml-class.github.io/), [Himabindu Lakkaraju](https://scholar.google.com/citations?user=oWid5PQAAAAJ&hl=en), Harvard, 2019.


