# Trustworthy Machine Learning

## Privacy and Confidentiality

### Data Inference Attacks

- Background

  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), [Thomas Steinke](https://scholar.google.com.sg/citations?user=kwnwhrgAAAAJ&hl=en), and [Jonathan Ullman](https://scholar.google.com.sg/citations?user=WfS41RAAAAAJ&hl=en). "**Exposed! a survey of attacks on private data**." In Annual Review of Statistics and Its Application, 2017. [[**paper**](https://projects.iq.harvard.edu/files/privacytools/files/pdf_02.pdf)]
  
- [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), Marco Stronati, [Congzheng Song](https://scholar.google.com/citations?user=lkPKfjgAAAAJ&hl=en), and [Vitaly Shmatikov](https://www.cs.cornell.edu/~shmat/). "**Membership inference attacks against machine learning models**." In IEEE Symposium on Security and Privacy (SP), 2017. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2017.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=rDm1n2gceJY)] [[**citations**](https://scholar.google.com.sg/scholar?cites=8935131557155912004&as_sdt=2005&sciodt=0,5&hl=en)]

- [Milad Nasr](https://scholar.google.com/citations?user=k6-nvDAAAAAJ&hl=en), [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Amir Houmansadr](https://scholar.google.com/citations?user=cTTFHNwAAAAJ&hl=en). "**Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning**." In IEEE Symposium on Security and Privacy (SP), 2019. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-SP2019.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=lzJY4BjCxTc)] [[**citations**](https://scholar.google.com.sg/scholar?oi=bibs&hl=en&cites=2009427570736671135,3616975283750298005,4006729549039865027)]

- [Congzheng Song](https://scholar.google.com/citations?user=lkPKfjgAAAAJ&hl=en), and [Ananth Raghunathan](https://scholar.google.com/citations?user=KQNjz6cAAAAJ&hl=en). "**Information Leakage in Embedding Models**." In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, 2020. [[**paper**](https://arxiv.org/pdf/2004.00053)]

#### Memorization 

- [Nicholas Carlini](https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en), Chang Liu, [Úlfar Erlingsson](https://scholar.google.com/citations?user=cX2HlhQAAAAJ&hl=en), Jernej Kos, and [Dawn Song](https://scholar.google.com/citations?user=84WzBlYAAAAJ&hl=en). "**The secret sharer: Evaluating and testing unintended memorization in neural networks**." In USENIX Security Symposium, 2019. [[**paper**](https://www.usenix.org/system/files/sec19-carlini.pdf)]  [[**conference talk**](https://www.youtube.com/watch?v=U9XbFtCWedE)] [[**citations**](https://scholar.google.com/scholar?cites=14719809661253001007&as_sdt=2005&sciodt=0,5&hl=en)]

- [Vitaly Feldman](https://scholar.google.com/citations?user=GqZBmfgAAAAJ&hl=en). "**Does learning require memorization? a short tale about a long tail**." In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, 2020. [[**paper**](https://arxiv.org/pdf/1906.05271)] [[**talk**](https://www.youtube.com/watch?v=Fp7cgHRl8Yc)] [[**follow-up paper**](https://arxiv.org/abs/2008.03703)] [[**citations**](https://scholar.google.com/scholar?cites=17943279247461969250&as_sdt=2005&sciodt=0,5&hl=en)]

### Model Inference Attacks

- [Florian Tramèr](https://scholar.google.com.sg/citations?user=ijH0-a8AAAAJ&hl=en&oi=sra), Fan Zhang, Ari Juels, Michael K. Reiter, and [Thomas Ristenpart](https://scholar.google.com.sg/citations?user=MGVrVSIAAAAJ&hl=en). "**Stealing machine learning models via prediction APIs**." In USENIX Security Symposium, 2016. [[**paper**](https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_tramer.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=qGjzmEzPkiI)] [[**citations**](https://scholar.google.com/scholar?cites=14391097248497422196&as_sdt=2005&sciodt=0,5&hl=en)]

- [Lejla Batina](https://scholar.google.com.sg/citations?user=jsDgMzkAAAAJ&hl=en), Shivam Bhasin, Dirmanto Jap, and Stjepan Picek. "**CSI NN: Reverse Engineering of Neural Network Architectures Through Electromagnetic Side Channel**." In USENIX Security Symposium, 2019. [[**paper**](https://www.usenix.org/system/files/sec19-batina.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=dZbrBILRz_c)]

- [Varun Chandrasekaran](https://scholar.google.com.sg/citations?user=Sl7nSOsAAAAJ&hl=en), [Kamalika Chaudhuri](https://scholar.google.com/citations?user=I-DJ7EsAAAAJ&hl=en), Irene Giacomelli, [Somesh Jha](https://scholar.google.com.sg/citations?user=BaI7l8QAAAAJ&hl=en), and Songbai Yan. "**Exploring Connections Between Active Learning and Model Extraction**." In USENIX Security Symposium, 2020. [[**paper**](https://www.usenix.org/system/files/sec20-chandrasekaran.pdf)] 

- [Matthew Jagielski](https://scholar.google.com.sg/citations?user=_8rw_GMAAAAJ&hl=en), [Nicholas Carlini](https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en), David Berthelot, Alex Kurakin, and [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en). "**High Accuracy and High Fidelity Extraction of Neural Networks**." In USENIX Security Symposium, 2020. [[**paper**](https://www.usenix.org/system/files/sec20-jagielski.pdf)]

### Privacy-Preserving Learning

- Background

  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), [Frank McSherry](https://scholar.google.com/citations?user=YYJ3aycAAAAJ&hl=en), [Kobbi Nissim](https://scholar.google.com/citations?user=U-RE8IgAAAAJ&hl=en), and [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en). "**Calibrating noise to sensitivity in private data analysis**." In Theory of cryptography conference, 2006. [[**paper**](https://iacr.org/archive/tcc2006/38760266/38760266.pdf)] 
  
  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), and [Aaron Roth](https://scholar.google.com/citations?user=kLUQrrYAAAAJ&hl=en). "**The algorithmic foundations of differential privacy**." Foundations and Trends in Theoretical Computer Science 9, 2014. [[**book**](https://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf)]

- [Kamalika Chaudhuri](https://scholar.google.com.sg/citations?user=I-DJ7EsAAAAJ&hl=en), Claire Monteleoni, and [Anand D. Sarwate](https://scholar.google.com.sg/citations?user=jgr1-eEAAAAJ&hl=en). "**Differentially private empirical risk minimization**." In Journal of Machine Learning Research 12, no. 3, 2011. [[**paper**](https://jmlr.csail.mit.edu/papers/volume12/chaudhuri11a/chaudhuri11a.pdf)] [[**tutorial talk at NIPS 2017**](https://vimeo.com/248492174)] [[**citations**](https://scholar.google.com.sg/scholar?cites=3955023019589847494&as_sdt=2005&sciodt=0,5&hl=en)]

- [Raef Bassily](https://scholar.google.com.sg/citations?user=C8qMVQUAAAAJ&hl=en), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), and [Abhradeep Thakurta](https://scholar.google.com.sg/citations?user=1rV69hMAAAAJ&hl=en). "**Private empirical risk minimization: Efficient algorithms and tight error bounds**." In IEEE 55th Annual Symposium on Foundations of Computer Science, 2014. [[**paper**](https://arxiv.org/pdf/1405.7085)] [[**talk by AT at MSR**](https://www.youtube.com/watch?v=djjO2sS3jac)] [[**follow-up paper**](https://robobees.seas.harvard.edu/files/privacytools/files/1405.7085v1.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=10593391545542726017&as_sdt=2005&sciodt=0,5&hl=en)]

- [Martin Abadi](https://scholar.google.com.sg/citations?user=vWTI60AAAAAJ&hl=en), Andy Chu, [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), [Brendan McMahan](https://scholar.google.com.sg/citations?user=iKPWydkAAAAJ&hl=en), [Ilya Mironov](https://scholar.google.com.sg/citations?user=hg3A9TgAAAAJ&hl=en), [Kunal Talwar](https://scholar.google.com.sg/citations?user=XD_01h8AAAAJ&hl=en), and Li Zhang. "**Deep learning with differential privacy**." In Proceedings of the ACM SIGSAC Conference on Computer and Communications Security, 2016. [[**paper**](https://arxiv.org/pdf/1607.00133)] [[**conference talk**](https://www.youtube.com/watch?v=ZxDBEyjiPxI)] [[**citations**](https://scholar.google.com.sg/scholar?cites=11431158613977668861&as_sdt=2005&sciodt=0,5&hl=en)]

- [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en), [Martin Abadi](https://scholar.google.com.sg/citations?user=vWTI60AAAAAJ&hl=en), [Úlfar Erlingsson](https://scholar.google.com/citations?user=cX2HlhQAAAAJ&hl=en), [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), and [Kunal Talwar](https://scholar.google.com.sg/citations?user=XD_01h8AAAAJ&hl=en). "**Semi-supervised knowledge transfer for deep learning from private training data**." In Proceedings of the 5th International Conference on Learning Representations, 2017. [[**paper**](https://arxiv.org/pdf/1610.05755)] [[**conference talk**](https://www.youtube.com/watch?v=bDayquwDgjU)] [[**follow-up paper**](https://arxiv.org/pdf/1802.08908)] [[**citations**](https://scholar.google.com.sg/scholar?cites=7453137533162499463&as_sdt=2005&sciodt=0,5&hl=en)]

- [Milad Nasr](https://scholar.google.com/citations?user=k6-nvDAAAAAJ&hl=en), [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Amir Houmansadr](https://scholar.google.com/citations?user=cTTFHNwAAAAJ&hl=en). "**Machine learning with membership privacy using adversarial regularization**." In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, 2018. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-CCS2018.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=53gELTL3ibA)] [[**citations**](https://scholar.google.com.sg/scholar?cites=8366684875630861099&as_sdt=2005&sciodt=0,5&hl=en)]

- Overview Talks

  - [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), "**Differential Privacy**." 2019. [[Tutorial](https://www.youtube.com/watch?v=Xz7k0wIW9nc)]
  
  - [Kunal Talwar](https://scholar.google.com.sg/citations?user=XD_01h8AAAAJ&hl=en), "**Large-Scale Private Learning**." 2019. [[Part I](https://www.youtube.com/watch?v=Cwx4LJutHt8)], [[Part II](https://www.youtube.com/watch?v=HsXJnW0Hi4k)]
  
  - [Ilya Mironov](https://scholar.google.com/citations?user=hg3A9TgAAAAJ&hl=en), "**Rényi Differential Privacy**." 2018. [[Talk](https://www.youtube.com/watch?v=oQzaA5KG3pM)]

### Confidential Computing

- [Payman Mohassel](https://scholar.google.com.sg/citations?user=g2xwfAMAAAAJ&hl=en&oi=sra), and Peter Rindal. "**ABY3: A mixed protocol framework for machine learning**." In Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security, 2018. [[**paper**](https://eprint.iacr.org/2018/403.pdf)]  [[**conference talk**](https://www.youtube.com/watch?v=X8l8XMNyHDM)] [[**citations**](https://scholar.google.com.sg/scholar?cites=9543562417119487548&as_sdt=2005&sciodt=0,5&hl=en)]

- [Chiraag Juvekar](https://scholar.google.com.sg/citations?user=i0OTdKIAAAAJ&hl=en), [Vinod Vaikuntanathan](https://scholar.google.com.sg/citations?user=a8jIPIkAAAAJ&hl=en), and [Anantha Chandrakasan](https://scholar.google.com.sg/citations?user=N6ah30sAAAAJ). "**GAZELLE: A low latency framework for secure neural network inference**." In 27th USENIX Security Symposium, 2018. [[**paper**](https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-juvekar.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=Aw6NScFMKXs)] [[**citations**](https://scholar.google.com.sg/scholar?cites=10196223049020093629&as_sdt=2005&sciodt=0,5&hl=en)]

- [Olga Ohrimenko](https://scholar.google.com/citations?user=lzfVm_8AAAAJ&hl=en), [Felix Schuster](https://scholar.google.de/citations?user=YKAVKXAAAAAJ&hl=en), [Cédric Fournet](https://scholar.google.de/citations?user=I30A7HcAAAAJ&hl=en), Aastha Mehta, Sebastian Nowozin, Kapil Vaswani, and Manuel Costa. "**Oblivious multi-party machine learning on trusted processors**." In 25th USENIX Security Symposium, 2016. [[**paper**](https://www.usenix.org/system/files/conference/usenixsecurity16/sec16_paper_ohrimenko.pdf)] [[**conference talk**](https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/ohrimenko)] [[**citations**](https://scholar.google.com.sg/scholar?cites=14174388165763279983&as_sdt=2005&sciodt=0,5&hl=en)] 

### Machine Unlearning

- [Lucas Bourtoule](https://scholar.google.com.sg/citations?user=Elvl65kAAAAJ&hl=en), [Varun Chandrasekaran](https://scholar.google.com.sg/citations?user=Sl7nSOsAAAAJ&hl=en), Christopher Choquette-Choo, Hengrui Jia, Adelin Travers, Baiwu Zhang, [David Lie](https://scholar.google.com.sg/citations?user=Qm_3B70AAAAJ&hl=en), and [Nicolas Papernot](https://scholar.google.com.sg/citations?user=cGxq0cMAAAAJ&hl=en). "**Machine unlearning**." arXiv preprint arXiv:1912.03817, 2019. [[**paper**](https://arxiv.org/pdf/1912.03817)]

- [Seth Neel](https://scholar.google.com.sg/citations?user=k4Q3TYwAAAAJ&hl=en), [Aaron Roth](https://scholar.google.com.sg/citations?user=kLUQrrYAAAAJ&hl=en), and [Saeed Sharifi-Malvajerdi](https://scholar.google.com.sg/citations?user=lRhBdecAAAAJ&hl=en). "**Descent-to-Delete: Gradient-Based Methods for Machine Unlearning**." arXiv preprint arXiv:2007.02923, 2020. [[**paper**](https://arxiv.org/pdf/2007.02923)]

### Decentralized (Collaborative, Federated) Learning

- [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Vitaly Shmatikov](https://www.cs.cornell.edu/~shmat/). "**Privacy-preserving deep learning**." In Proceedings of the 22nd ACM SIGSAC conference on computer and communications security, 2015. [[**paper**](https://www.comp.nus.edu.sg/~reza/files/Shokri-CCS2015.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=13974194320253379739&as_sdt=2005&sciodt=0,5&hl=en)]

- [Brendan McMahan](https://scholar.google.com.sg/citations?user=iKPWydkAAAAJ&hl=en), Eider Moore, [Daniel Ramage](https://scholar.google.com.sg/citations?user=D0NeJxMAAAAJ&hl=en), Seth Hampson, and Blaise Aguera y Arcas. "**Communication-efficient learning of deep networks from decentralized data**." In Artificial Intelligence and Statistics, 2017. [[**paper**](https://arxiv.org/pdf/1602.05629)] [[**citations**](https://scholar.google.com.sg/scholar?oi=bibs&hl=en&cites=121527355242954284&as_sdt=5)]

- [Virginia Smith](https://scholar.google.com.sg/citations?user=bldHpWIAAAAJ&hl=en), [Chao-Kai Chiang](https://scholar.google.com.sg/citations?user=pBQgK_YAAAAJ&hl=en), [Maziar Sanjabi](https://scholar.google.com.sg/citations?user=bc_N2-oAAAAJ&hl=en), and [Ameet S. Talwalkar](https://scholar.google.co.th/citations?user=TW7U1W0AAAAJ&hl=en). "**Federated multi-task learning**." In Advances in Neural Information Processing Systems, 2017. [[**paper**](http://papers.nips.cc/paper/7029-federated-multi-task-learning.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=2729989706953112243&as_sdt=2005&sciodt=0,5&hl=en)]

- [Peter Kairouz](https://scholar.google.com.sg/citations?user=m8NUgw0AAAAJ&hl=en) et al. "**Advances and open problems in federated learning**." arXiv preprint arXiv:1912.04977, 2019. [[**paper**](https://arxiv.org/pdf/1912.04977)]

### Law and Policy

- [Kobbi Nissim](https://scholar.google.com/citations?user=U-RE8IgAAAAJ&hl=en), [Aaron Bembenek](https://scholar.google.com/citations?user=Ql2u7VoAAAAJ&hl=en), [Alexandra Wood](https://cyber.harvard.edu/people/awood), [Mark Bun](https://scholar.google.com/citations?user=oDwLyYUAAAAJ&hl=en), [Marco Gaboardi](https://scholar.google.com/citations?user=5b8D1MgAAAAJ&hl=en), [Urs Gasser](https://cyber.harvard.edu/people/ugasser), [David R. O'Brien](https://cyber.harvard.edu/people/dobrien), [Thomas Steinke](https://scholar.google.com/citations?user=kwnwhrgAAAAJ&hl=en), and [Salil Vadhan](https://scholar.google.com/citations?user=dqVjyRQAAAAJ&hl=en). "**Bridging the gap between computer science and legal approaches to privacy**." Harvard Journal of Law & Technology, Volume 31, 2018. [[**paper**](https://dash.harvard.edu/bitstream/handle/1/37355739/Bridging_the_Gap_between_Computer_Science_and_Legal_Approaches_to_Privacy.pdf)] [[**talk by KN**](https://www.youtube.com/watch?v=4FRbAmXvec8)] [[**citations**](https://scholar.google.com/scholar?cites=12818689832408026903&as_sdt=2005&sciodt=0,5&hl=en)]

### Tools and Libraries

- [Open Differential Privacy](https://github.com/opendifferentialprivacy)

- [TensorFlow Privacy](https://github.com/tensorflow/privacy)

- [TF Encrypted](https://tf-encrypted.io/) [[**talk**](https://www.youtube.com/watch?v=kiB882Gphlc)]

- [ML Privacy Meter](https://github.com/privacytrustlab/ml_privacy_meter) [[**talk**](https://www.youtube.com/watch?v=DWqnKNZTz10)]

### Related Courses and Schools

- [Data Privacy: Foundations and Applications](https://simons.berkeley.edu/programs/privacy2019), Simons Institute for the Theory of Computing, 2019. 

- [Applied Privacy for Data Science](http://people.seas.harvard.edu/~salil/cs208/), [James Honaker](https://scholar.google.com/citations?user=q0WV4cgAAAAJ&hl=en) and [Salil Vadhan](https://scholar.google.com/citations?user=dqVjyRQAAAAJ&hl=en), Harvard, 2019.

- [Privacy in Machine Learning and Statistical Inference](https://docs.google.com/document/d/1jsZLEd3ZM-ZWdNAjNRI4_bgPysRUsKQDHvy4VKgtzJ8/edit), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en), Boston University, 2018.

- [The Algorithmic Foundations of Adaptive Data Analysis](https://adaptivedataanalysis.com/), [Adam Smith](https://scholar.google.com.sg/citations?user=fkGi-JMAAAAJ&hl=en) and [Aaron Roth](https://scholar.google.com/citations?user=kLUQrrYAAAAJ&hl=en), UPenn and Boston University, 2017.


## Robustness

### Training Phase

- Background

  - [Ilias Diakonikolas](https://scholar.google.com/citations?user=Vb3FLmkAAAAJ&hl=en), and [Daniel M. Kane](https://scholar.google.com/citations?user=DulpV-cAAAAJ&hl=en). "**Recent advances in algorithmic high-dimensional robust statistics**." arXiv preprint arXiv:1911.05911, 2019. [[**paper**](https://arxiv.org/pdf/1911.05911)]
  
  - [Ankur Moitra](https://scholar.google.com/citations?hl=en&user=umFQktIAAAAJ), "**Robustness Meets Algorithms**." 2019. [[**Talk**](https://www.youtube.com/watch?v=qxZQml1897Q)] 

- [Chiyuan Zhang](https://scholar.google.com.sg/citations?user=l_G2vr0AAAAJ&hl=en), [Samy Bengio](https://scholar.google.com.sg/citations?user=Vs-MdPcAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en), [Benjamin Recht](https://scholar.google.com.sg/citations?user=a_dbdxAAAAAJ&hl=en), and [Oriol Vinyals](https://scholar.google.com.sg/citations?user=NkzyCvUAAAAJ&hl=en). "**Understanding deep learning requires rethinking generalization**." In International Conference on Learning Representations, 2017. [[**paper**](https://arxiv.org/pdf/1611.03530)] [[**conference talk**](https://www.youtube.com/watch?v=kCj51pTQPKI)] [[**citations**](https://scholar.google.com.sg/scholar?cites=4613672282544622621&as_sdt=2005&sciodt=0,5&hl=en)]

- [Jacob Steinhardt](https://scholar.google.com/citations?user=LKv32bgAAAAJ&hl=en), [Pang Wei W. Koh](https://scholar.google.com/citations?user=Nn990CkAAAAJ&hl=en), and [Percy S. Liang](https://scholar.google.com/citations?user=pouyVyUAAAAJ&hl=en). "**Certified defenses for data poisoning attacks**." In Advances in neural information processing systems, 2017. [[**paper**](http://papers.nips.cc/paper/6943-certified-defenses-for-data-poisoning-attacks.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=10474944557566613837&as_sdt=2005&sciodt=0,5&hl=en)]

- [Elan Rosenfeld](https://scholar.google.com/citations?user=f0j0K8QAAAAJ&hl=en), Ezra Winston, [Pradeep Ravikumar](https://scholar.google.com/citations?user=Q4DTPw4AAAAJ&hl=en), and [Zico Kolter](https://scholar.google.com.sg/citations?user=UXh1I6UAAAAJ&hl=en). "**Certified Robustness to Label-Flipping Attacks via Randomized Smoothing**." In International Conference on Machine Learning, 2020. [[**paper**](https://arxiv.org/pdf/2002.03018)]

### Inference Phase

- [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), [Jonathon Shlens](https://scholar.google.com.sg/citations?user=x5bC-UwAAAAJ&hl=en), and [Christian Szegedy](https://scholar.google.com.sg/citations?user=3QeF7mAAAAAJ&hl=en). "**Explaining and harnessing adversarial examples**." International Conference on Learning Representations, 2015. [[**paper**](https://arxiv.org/pdf/1412.6572)] [[**citations**](https://scholar.google.com.sg/scholar?cites=14908107896544813002&as_sdt=2005&sciodt=0,5&hl=en)] [follow-ups: [**black-box**](https://arxiv.org/pdf/1602.02697), [**transferability**](https://arxiv.org/pdf/1605.07277), [**universal perturbation**](https://arxiv.org/pdf/1610.08401), [**detection**](https://arxiv.org/pdf/1705.07263), [**physical world**](https://arxiv.org/pdf/1707.08945.pdf)] 

- [Nicholas Carlini](https://scholar.google.com/citations?user=q4qDvAoAAAAJ&hl=en), and [David Wagner](https://scholar.google.com/citations?user=67kghxAAAAAJ&hl=en). "**Towards evaluating the robustness of neural networks**." In IEEE symposium on security and privacy (SP), 2017. [[**paper**](https://www.ieee-security.org/TC/SP2017/papers/518.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=yIXNL88JBWQ)] [[**citations**](https://scholar.google.com/scholar?cites=6732985638826567603&as_sdt=2005&sciodt=0,5&hl=en)]

- [Aleksander Madry](https://scholar.google.com/citations?user=SupjsEUAAAAJ&hl=en), [Aleksandar Makelov](https://scholar.google.com/citations?user=haO4sKoAAAAJ&hl=en), [Ludwig Schmidt](https://scholar.google.com/citations?user=SWMKy70AAAAJ&hl=en), [Dimitris Tsipras](https://scholar.google.com/citations?user=26eh1jAAAAAJ&hl=en), and [Adrian Vladu](https://scholar.google.com/citations?user=5qh5cc0AAAAJ&hl=en). "**Towards Deep Learning Models Resistant to Adversarial Attacks**." In International Conference on Learning Representations, 2018. [[**paper**](https://arxiv.org/pdf/1706.06083)] [[**citations**](https://scholar.google.com/scholar?cites=14165082781627851489&as_sdt=2005&sciodt=0,5&hl=en)]

- [Jeremy Cohen](https://scholar.google.com.sg/citations?user=r493814AAAAJ&hl=en), [Elan Rosenfeld](https://scholar.google.com.sg/citations?user=f0j0K8QAAAAJ&hl=en), and [Zico Kolter](https://scholar.google.com.sg/citations?user=UXh1I6UAAAAJ&hl=en). "**Certified Adversarial Robustness via Randomized Smoothing**." In International Conference on Machine Learning, 2019. [[**paper**](https://arxiv.org/pdf/1902.02918)] [[**talk by ZK**](https://www.youtube.com/watch?v=UHs2mGBH0Fg)] [[**citations**](https://scholar.google.com/scholar?cites=7039519782328477041&as_sdt=2005&sciodt=0,5&hl=en)]

- [Yair Carmon](https://scholar.google.com/citations?user=kTKmpT0AAAAJ&hl=en), [Aditi Raghunathan](https://scholar.google.com/citations?user=Ch9iRwQAAAAJ&hl=en), [Ludwig Schmidt](https://scholar.google.com/citations?user=SWMKy70AAAAJ&hl=en), [John C. Duchi](https://scholar.google.com/citations?user=i5srt20AAAAJ&hl=en), and [Percy S. Liang](https://scholar.google.com/citations?user=pouyVyUAAAAJ&hl=en). "**Unlabeled data improves adversarial robustness**." In Advances in Neural Information Processing Systems, 2019. [[**paper**](https://papers.nips.cc/paper/9298-unlabeled-data-improves-adversarial-robustness.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=5182550296368877701&as_sdt=2005&sciodt=0,5&hl=en)]

- [Sanghyun Hong](https://scholar.google.com/citations?user=664LW90AAAAJ&hl=en), [Pietro Frigo](https://scholar.google.com/citations?user=WJLYoXcAAAAJ&hl=en), [Yiğitcan Kaya](https://scholar.google.com/citations?user=tPiXuV0AAAAJ&hl=en), [Cristiano Giuffrida](https://scholar.google.com/citations?user=2QmtNQsAAAAJ&hl=en), and [Tudor Dumitraș](https://scholar.google.com/citations?user=f6terwoAAAAJ&hl=en). "**Terminal brain damage: Exposing the graceless degradation in deep neural networks under hardware fault attacks**." In USENIX Security Symposium, 2019. [[**paper**](https://www.usenix.org/system/files/sec19-hong.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=o_CY-cFNfRo)]

- Overview Talks

  - [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), "**Adversarial Examples and Adversarial Training**." 2017. [[Lecture](https://www.youtube.com/watch?v=CIfsB_EYsVI)]
  
  - [Zico Kolter](https://scholar.google.com.sg/citations?user=UXh1I6UAAAAJ&hl=en) and [Aleksander Madry](https://scholar.google.com/citations?user=SupjsEUAAAAJ&hl=en), "**Adversarial Robustness - Theory and Practice**." 2018. [[NeurIPS Tutorial](https://www.youtube.com/watch?v=TwP-gKBQyic)]
  
  - [Aleksander Madry](https://scholar.google.com/citations?user=SupjsEUAAAAJ&hl=en), "**A New Perspective on Adversarial Perturbations**." 2019. [[**talk**](https://www.youtube.com/watch?v=mUt7w4UoYqM)]
  
### Testing and Verification

- [Guy Katz](https://scholar.google.com/citations?user=3nYG5BMAAAAJ&hl=en), [Clark Barrett](https://scholar.google.com/citations?user=BtwmZfQAAAAJ&hl=en), [David L. Dill](https://scholar.google.com/citations?user=uy8T6BYAAAAJ&hl=en), [Kyle Julian](https://scholar.google.com/citations?user=NlnpI7QAAAAJ&hl=en), and [Mykel J. Kochenderfer](https://scholar.google.com/citations?user=cAy9G6oAAAAJ&hl=en). "**Reluplex: An efficient SMT solver for verifying deep neural networks**." In International Conference on Computer Aided Verification, 2017. [[**paper**](https://arxiv.org/pdf/1610.06940)] [[**conference talk**](https://www.youtube.com/watch?v=KiKS_zaPb64)] [[**citations**](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16898270665626409672)]

- [Gagandeep Singh](https://scholar.google.com/citations?user=m4b2ruEAAAAJ&hl=en), [Timon Gehr](https://scholar.google.com/citations?user=HcL76tsAAAAJ&hl=en), [Markus Püschel](https://scholar.google.com/citations?user=az9ZryAAAAAJ&hl=en), and [Martin Vechev](https://scholar.google.com/citations?user=aZ1Rh50AAAAJ&hl=en). "**An abstract domain for certifying neural networks**." Proceedings of the ACM on Programming Languages (POPL), 2019. [[**paper**](https://files.sri.inf.ethz.ch/website/papers/DeepPoly.pdf)] [[**conference talk**](https://www.youtube.com/watch?v=5Tkc1kgCXRI)] [[**citations**](https://scholar.google.com/scholar?cites=17913918431933235756&as_sdt=2005&sciodt=0,5&hl=en)]

### Tools and Libraries

- [CleverHans](https://github.com/tensorflow/cleverhans)


## Algorithmic Fairness

- Overview

  - [Alexandra Chouldechova](https://scholar.google.com.sg/citations?user=uoDW9hkAAAAJ&hl=en), and [Aaron Roth](https://scholar.google.com.sg/citations?user=kLUQrrYAAAAJ&hl=en). "**The frontiers of fairness in machine learning**." arXiv preprint arXiv:1810.08810, 2018. [[**paper**](https://arxiv.org/pdf/1810.08810)]
  
  - [Solon Barocas](https://scholar.google.com/citations?user=rEjgIskAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), and [Arvind Narayanan](https://scholar.google.com/citations?user=0Bi5CMgAAAAJ&hl=en). "**Fairness and machine learning: Limitations and Opportunities**." Work in progress book, 2019. [[**book**](https://fairmlbook.org/pdf/fairmlbook.pdf)]

- Overview Talks

  - [Solon Barocas](https://scholar.google.com/citations?user=rEjgIskAAAAJ&hl=en) and [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), "**Fairness in machine learning**." [[**Tutorial at NIPS**](https://vimeo.com/248490141)], 2017.
  
  - [Arvind Narayanan](https://scholar.google.com/citations?user=0Bi5CMgAAAAJ&hl=en), "**21 fairness definitions and their politics**." 2018. [[**Tutorial**](https://www.youtube.com/watch?v=jIXIuYdnyyk)]
  
  - [Cynthia Dwork](https://scholar.google.com.sg/citations?user=y2H5xmkAAAAJ&hl=en), "**The Emerging Theory of Algorithmic Fairness**." 2018. [[**Talk**](https://www.youtube.com/watch?v=g-z84_nRQhw)]
  
  - [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), "**Fairness**." [[**Part I**](https://www.youtube.com/watch?v=Igq_S_7IfOU)], [[**Part II**](https://www.youtube.com/watch?v=9oNVFQ9llPc)]
  
  - [Suresh Venkatasubramanian](https://scholar.google.com.sg/citations?user=Z03FLwkAAAAJ&hl=en), "**Algorithmic Fairness and Unfairness: A New Research Area**." 2019. [[**Talk**](https://www.youtube.com/watch?v=uneZRF6Rm08)] 
  
### Measures 

- [Cynthia Dwork](https://scholar.google.com/citations?user=y2H5xmkAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), Toniann Pitassi, [Omer Reingold](https://scholar.google.com/citations?user=TD9RhcgAAAAJ&hl=en), and [Richard Zemel](https://scholar.google.com/citations?user=iBeDoRAAAAAJ&hl=en). "**Fairness through awareness**." In Proceedings of the 3rd innovations in theoretical computer science conference, 2012. [[**paper**](https://arxiv.org/pdf/1104.3913)] [[**citations**](https://scholar.google.com/scholar?cites=15887350027958465759&as_sdt=2005&sciodt=0,5&hl=en)]

- [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en), [Eric Price](https://scholar.google.com/citations?user=UE6z_m8AAAAJ&hl=en), and [Nati Srebro](https://scholar.google.com/citations?user=ZnT-QpMAAAAJ&hl=en). "**Equality of opportunity in supervised learning**." In Advances in neural information processing systems, 2016. [[**paper**](http://papers.nips.cc/paper/6374-equality-of-opportunity-in-supervised-learning.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=2062984936384963570&as_sdt=2005&sciodt=0,5&hl=en)]

- [Matt J. Kusner](https://scholar.google.com/citations?user=57KRSu8AAAAJ&hl=en), [Joshua Loftus](https://scholar.google.com/citations?user=SIbr3XUAAAAJ&hl=en), [Chris Russell](https://scholar.google.com/citations?user=RM2sHhYAAAAJ&hl=en), and [Ricardo Silva](https://scholar.google.com/citations?user=I-ANa0QAAAAJ&hl=en). "**Counterfactual fairness**." In Advances in neural information processing systems, 2017. [[**paper**](http://papers.nips.cc/paper/6995-counterfactual-fairness.pdf)] [[**talk by MK**](https://www.youtube.com/watch?v=ZfuOw02U7hs)] [[**citations**](https://scholar.google.com/scholar?cites=13115459093902017069&as_sdt=2005&sciodt=0,5&hl=en)]

### Mechanisms

- [Rich Zemel](https://scholar.google.com.sg/citations?user=iBeDoRAAAAAJ&hl=en), [Yu Wu](https://scholar.google.com.sg/citations?user=-eJHVt8AAAAJ&hl=en), [Kevin Swersky](https://scholar.google.com.sg/citations?user=IrixA8MAAAAJ&hl=en), Toni Pitassi, and [Cynthia Dwork](https://scholar.google.com/citations?user=y2H5xmkAAAAJ&hl=en). "**Learning fair representations**." In International Conference on Machine Learning, 2013. [[**paper**](http://www.jmlr.org/proceedings/papers/v28/zemel13.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=6130171396735864663&as_sdt=2005&sciodt=0,5&hl=en)]

- Michael Feldman, [Sorelle A. Friedler](https://scholar.google.com/citations?user=XDHr1VIAAAAJ&hl=en), [John Moeller](https://scholar.google.com/citations?user=AUHBWKIAAAAJ&hl=en), [Carlos Scheidegger](https://scholar.google.com.sg/citations?user=8uHMJjsAAAAJ&hl=en), and [Suresh Venkatasubramanian](https://scholar.google.com.sg/citations?user=Z03FLwkAAAAJ&hl=en). "**Certifying and removing disparate impact**." In proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining, 2015. [[**paper**](https://arxiv.org/pdf/1412.3756)] [[**conference talk**](https://www.youtube.com/watch?v=4ds9fBDtMmU)] [[**citations**](https://scholar.google.com.sg/scholar?oi=bibs&hl=en&cites=9404979763053543288&as_sdt=5)]

- [Muhammad Bilal Zafar](https://scholar.google.com.sg/citations?user=keWdp0AAAAAJ&hl=en), [Isabel Valera](https://scholar.google.com.sg/citations?user=cpdQqpsAAAAJ&hl=en), [Manuel Gomez Rogriguez](https://scholar.google.com.sg/citations?user=UcuXmuwAAAAJ&hl=en), and [Krishna P. Gummadi](https://scholar.google.com.sg/citations?user=Bz3APTsAAAAJ&hl=en). "**Fairness constraints: Mechanisms for fair classification**." In Artificial Intelligence and Statistics, 2017. [[**paper**](http://proceedings.mlr.press/v54/zafar17a/zafar17a.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=13152667258933603266&as_sdt=2005&sciodt=0,5&hl=en)]

- [Alekh Agarwal](https://scholar.google.com/citations?user=9nnDvooAAAAJ&hl=en), Alina Beygelzimer, [Miroslav Dudík](https://scholar.google.com/citations?user=wYMTld8AAAAJ&hl=en), [John Langford](https://scholar.google.com/citations?user=LFiqVpwAAAAJ&hl=en), and [Hanna Wallach](https://scholar.google.com/citations?user=OcPVegoAAAAJ&hl=en). "**A reductions approach to fair classification**." In International Conference on Machine Learning, 2018. [[**paper**](https://arxiv.org/pdf/1803.02453)] [[**citations**](https://scholar.google.com/scholar?cites=16870675827052455946&as_sdt=2005&sciodt=0,5&hl=en)]

### Analysis

- [Jon Kleinberg](https://scholar.google.com/citations?user=VX7d5EQAAAAJ&hl=en), [Sendhil Mullainathan](https://scholar.google.com/citations?user=oExfyEkAAAAJ&hl=en), and [Manish Raghavan](https://scholar.google.com/citations?user=WaGlwJ4AAAAJ&hl=en). "**Inherent trade-offs in the fair determination of risk scores**." arXiv preprint arXiv:1609.05807, 2016. [[**paper**](https://arxiv.org/pdf/1609.05807)] [[**talk by JK**](https://www.youtube.com/watch?v=K7i_tnflZ64)] [[**citations**](https://scholar.google.com.sg/scholar?cites=17988184943074251625&as_sdt=2005&sciodt=0,5&hl=en)]

- [Sam Corbett-Davies](https://scholar.google.com.sg/citations?user=sKDlVpwAAAAJ&hl=en), [Emma Pierson](https://scholar.google.com.sg/citations?user=xGORWi0AAAAJ&hl=en)], [Avi Feller](https://scholar.google.com.sg/citations?user=Mz7heb4AAAAJ&hl=en), [Sharad Goel](https://scholar.google.com.sg/citations?user=Vv8UdowAAAAJ&hl=en), and Aziz Huq. "**Algorithmic decision making and the cost of fairness**." In Proceedings of the 23rd acm SIGKDD international conference on knowledge discovery and data mining, 2017. [[**paper**](https://arxiv.org/pdf/1701.08230)] [[**talk by SCD**](https://www.youtube.com/watch?v=pm2IVjnnMRY)] [[**citations**](https://scholar.google.com.sg/scholar?cites=2698186144635429170&as_sdt=2005&sciodt=0,5&hl=en)]

- [Lydia T. Liu](https://scholar.google.com.sg/citations?user=IQ2eTA8AAAAJ&hl=en), [Sarah Dean](https://scholar.google.com.sg/citations?user=xhKqjpYAAAAJ&hl=en), [Esther Rolf](https://scholar.google.com.sg/citations?user=n1EE3-8AAAAJ&hl=en), [Max Simchowitz](https://scholar.google.com.sg/citations?user=QhG_7egAAAAJ&hl=en), and [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en). "**Delayed impact of fair machine learning**." In International Conference on Machine Learning, 2018. [[**paper**](http://proceedings.mlr.press/v80/liu18c/liu18c.pdf)] [[**talk by LL**](https://www.youtube.com/watch?v=8cDVtXjvq9s)] [[**citations**](https://scholar.google.com/scholar?client=firefox-b-d&um=1&ie=UTF-8&lr&cites=5181623229195224544)]

### Robustness

- [Avrim Blum](https://scholar.google.com.sg/citations?user=Jlv4MR4AAAAJ&hl=en), and [Kevin Stangl](https://scholar.google.com.sg/citations?user=76AAneMAAAAJ&hl=en). "**Recovering from biased data: Can fairness constraints improve accuracy?**." In 1st Symposium on Foundations of Responsible Computing (FORC), 2020. [[**paper**](https://arxiv.org/pdf/1912.01094)]  [[**conference talk**](https://www.youtube.com/watch?v=O0qfqZ7HHuY)]

- [Heinrich Jiang](https://scholar.google.com.sg/citations?user=RiDdF2YAAAAJ&hl=en), and [Ofir Nachum](https://scholar.google.com.sg/citations?user=C-ZlBWMAAAAJ&hl=en). "**Identifying and correcting label bias in machine learning**." In International Conference on Artificial Intelligence and Statistics, 2020. [[**paper**](http://proceedings.mlr.press/v108/jiang20a/jiang20a.pdf)]

- Hongyan Chang, Ta Duy Nguyen, Sasi Kumar Murakonda, [Ehsan Kazemi](https://scholar.google.com.sg/citations?user=kdyalCwAAAAJ&hl=en), and [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en). "**On Adversarial Bias and the Robustness of Fair Machine Learning**." arXiv preprint arXiv:2006.08669, 2020. [[**paper**](https://arxiv.org/pdf/2006.08669)]

### Related Courses and Schools

- [Recent Developments in Research on Fairness](https://simons.berkeley.edu/workshops/schedule/10758), Simons Institute for the Theory of Computing, 2019.

- [Fairness in Machine Learning](https://fairmlclass.github.io/), [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en), UC Berkeley, 2017.

- [Fairness in Machine Learning](https://docs.google.com/document/d/1XnbJXELA0L3CX41MxySdPsZ-HNECxPtAw4-kZRc7OPI/edit), [Arvind Narayanan](https://scholar.google.com/citations?user=0Bi5CMgAAAAJ&hl=en), Princeton, 2017.

- [Human-Centered Machine Learning](http://courses.mpi-sws.org/hcml-ws18/schedule.html), [Krishna P. Gummadi](https://scholar.google.com.sg/citations?user=Bz3APTsAAAAJ&hl=en), MPI-Software, 2018.


## Algorithmic Transparency

- [Finale Doshi-Velez](https://scholar.google.com.sg/citations?user=hwQtFB0AAAAJ&hl=en), and [Been Kim](https://scholar.google.com.sg/citations?user=aGXkhcwAAAAJ&hl=en). "**Towards a rigorous science of interpretable machine learning**." arXiv preprint arXiv:1702.08608, 2017. [[**paper**](https://arxiv.org/pdf/1702.08608)] [[**talk by FDV**](https://www.youtube.com/watch?v=MMxZlr_L6YE)]

- [Brent Mittelstadt](https://scholar.google.com.sg/citations?user=tP685zYAAAAJ&hl=en), [Chris Russell](https://scholar.google.com.sg/citations?user=RM2sHhYAAAAJ&hl=en), and [Sandra Wachter](https://scholar.google.com.sg/citations?user=ZXBJVqYAAAAJ&hl=en). "**Explaining explanations in AI**." In Proceedings of the conference on fairness, accountability, and transparency, 2019. [[**paper**](https://arxiv.org/pdf/1811.01439)]

- Overview talks

  - [Cynthia Rudin](https://scholar.google.com/citations?user=mezKJyoAAAAJ&hl=en). "**Do Simpler Models Exist and How Can We Find Them?**." [[**keynote talk at KDD**](https://www.youtube.com/watch?v=wL4X4lG20sM)]
  
  - [Rich Caruana](https://scholar.google.com/citations?user=B2U8EUwAAAAJ&hl=en). "**Friends Don’t Let Friends Deploy Black-Box Models: Intelligibility in Machine Learning for Bias Detection and Correction**." [[**talk**](https://www.youtube.com/watch?v=TPY16CSIrwY)]

### Model Explanation

- [Sandra Wachter](https://scholar.google.com.sg/citations?user=ZXBJVqYAAAAJ&hl=en), [Brent Mittelstadt](https://scholar.google.com.sg/citations?user=tP685zYAAAAJ&hl=en), and [Chris Russell](https://scholar.google.com.sg/citations?user=RM2sHhYAAAAJ&hl=en). "**Counterfactual explanations without opening the black box: Automated decisions and the GDPR**." Harvard Journal of Law & Technology, 2017. [[**paper**](https://jolt.law.harvard.edu/assets/articlePDFs/v31/Counterfactual-Explanations-without-Opening-the-Black-Box-Sandra-Wachter-et-al.pdf)] [[**citations**](https://scholar.google.com.sg/scholar?cites=5948704720199512282&as_sdt=2005&sciodt=0,5&hl=en)]

- [Marco Tulio Ribeiro](https://scholar.google.com.sg/citations?user=rmsIyGMAAAAJ&hl=en), [Sameer Singh](https://scholar.google.com.sg/citations?user=-hGZC54AAAAJ&hl=en), and [Carlos Guestrin](https://scholar.google.com.sg/citations?user=DpLFv4gAAAAJ&hl=en). "**"Why should I trust you?" Explaining the predictions of any classifier**." In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, 2016. [[**paper**](https://arxiv.org/pdf/1602.04938)] [[**conference talk**](https://www.youtube.com/watch?v=KP7-JtFMLo4)] [[**talk by SS**](https://www.youtube.com/watch?v=LAm4QmVaf0E)] [[**citations**](https://scholar.google.com.sg/scholar?cites=16724302923321127943&as_sdt=2005&sciodt=0,5&hl=en)] 

- [Scott M. Lundberg](https://scholar.google.com/citations?user=ESRugcEAAAAJ&hl=en), and [Su-In Lee](https://scholar.google.com/citations?user=3ifikJ0AAAAJ&hl=en). "**A unified approach to interpreting model predictions**." In Advances in neural information processing systems, 2017. [[**paper**](http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf)] [[**citations**](https://scholar.google.com/scholar?cites=6828961408019591083&as_sdt=2005&sciodt=0,5&hl=en)]

- [Anupam Datta](https://scholar.google.com/citations?user=oK3QM1wAAAAJ&hl=en), [Shayak Sen](https://scholar.google.com/citations?user=vdiw0xMAAAAJ&hl=en), and [Yair Zick](https://scholar.google.com/citations?user=m0PW6DQAAAAJ&hl=en). "**Algorithmic transparency via quantitative input influence: Theory and experiments with learning systems**." In IEEE symposium on security and privacy (SP), 2016. [[**paper**](https://www.andrew.cmu.edu/user/danupam/datta-sen-zick-oakland16.pdf)] [[**talk by AD**](https://youtu.be/Q6UuncHgUaA?t=1623)] [[**citations**](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14953509643678714899&as_sdt=5)]

### Interpretability

- [Cynthia Rudin](https://scholar.google.com/citations?user=mezKJyoAAAAJ&hl=en). "**Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead**." Nature Machine Intelligence 1, 2019. [[**paper**](https://arxiv.org/pdf/1811.10154)]

### Recourse

- [Berk Ustun](https://scholar.google.com.sg/citations?user=6z_XWYcAAAAJ&hl=en), [Alexander Spangher](https://scholar.google.com.sg/citations?user=pZEaPR8AAAAJ&hl=en), and [Yang Liu](https://scholar.google.com.sg/citations?user=jKrIVCIAAAAJ&hl=en). "**Actionable recourse in linear classification**." In Proceedings of the Conference on Fairness, Accountability, and Transparency, 2019. [[**paper**](https://arxiv.org/pdf/1809.06514)] [[**conference talk**](https://youtu.be/iZM4_YNw4Mw)] [[**citations**](https://scholar.google.com.sg/scholar?cites=9971779227054924463&as_sdt=2005&sciodt=0,5&hl=en)]

### Robustness

- [Julius Adebayo](https://scholar.google.com.sg/citations?user=y1bnRg4AAAAJ&hl=en), [Justin Gilmer](https://scholar.google.com.sg/citations?user=Ml_vQ8MAAAAJ&hl=en), [Michael Muelly](https://scholar.google.com.sg/citations?user=F2SAhnQAAAAJ&hl=en), [Ian Goodfellow](https://scholar.google.com.sg/citations?user=iYN86KEAAAAJ&hl=en), [Moritz Hardt](https://scholar.google.com.sg/citations?user=adnTgaAAAAAJ&hl=en), and [Been Kim](https://scholar.google.com.sg/citations?user=aGXkhcwAAAAJ&hl=en). "**Sanity checks for saliency maps**." In Advances in Neural Information Processing Systems, 2018. [[**paper**](http://papers.neurips.cc/paper/8160-sanity-checks-for-saliency-maps.pdf)] [[**conference talk**](https://www.facebook.com/nipsfoundation/videos/515859272265612/)],starts at 53', [[**citations**](https://scholar.google.com.sg/scholar?cites=8767887416569707674&as_sdt=2005&sciodt=0,5&hl=en)]

- [Amirata Ghorbani](https://scholar.google.com.sg/citations?user=BtgIFycAAAAJ&hl=en), [Abubakar Abid](https://scholar.google.com.sg/citations?user=8slGl3oAAAAJ&hl=en), and [James Zou](https://scholar.google.com.sg/citations?user=23ZXZvEAAAAJ&hl=en). "**Interpretation of neural networks is fragile**." In Proceedings of the AAAI Conference on Artificial Intelligence, 2019. [[**paper**](https://arxiv.org/pdf/1710.10547)] [[**conference talk**](https://www.youtube.com/watch?v=8KyZCmBTPNw)] [[**citations**](https://scholar.google.com/scholar?cites=8913730552362106675&as_sdt=2005&sciodt=0,5&hl=en)]

- [Dylan Slack](https://scholar.google.com/citations?user=pyhz-gUAAAAJ&hl=en), Sophie Hilgard, Emily Jia, [Sameer Singh](https://scholar.google.com/citations?user=-hGZC54AAAAJ&hl=en), and [Himabindu Lakkaraju](https://scholar.google.com/citations?user=oWid5PQAAAAJ&hl=en). "**Fooling lime and shap: Adversarial attacks on post hoc explanation methods**." In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society, 2020. [[**paper**](https://arxiv.org/pdf/1911.02508)] [[**talk by HL**](https://www.youtube.com/watch?v=4HyJIOenIlI)] [[**citations**](https://scholar.google.com/scholar?cites=8884301126625541721&as_sdt=2005&sciodt=0,5&hl=en)]

### Privacy and Confidentiality

- [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), [Martin Strobel](https://scholar.google.com/citations?user=6p4Fg_wAAAAJ&hl=en), and [Yair Zick](https://scholar.google.com/citations?user=m0PW6DQAAAAJ&hl=en). "**On the Privacy Risks of Model Explanations**." arXiv preprint arXiv:1907.00164, 2019. [[**paper**](https://arxiv.org/pdf/1907.00164)] [[**citations**](https://scholar.google.com/scholar?cites=1863276377879092856&as_sdt=2005&sciodt=0,5&hl=en)]

- [Neel Patel](https://scholar.google.com/citations?user=zN081ZcAAAAJ&hl=en), [Reza Shokri](https://scholar.google.com/citations?user=udlZXXcAAAAJ&hl=en), and [Yair Zick](https://scholar.google.com/citations?user=m0PW6DQAAAAJ&hl=en). "**Model Explanations with Differential Privacy**." arXiv preprint arXiv:2006.09129, 2020. [[**paper**](https://arxiv.org/pdf/2006.09129)] 

- [Smitha Milli](https://scholar.google.com/citations?user=tsXh_hwAAAAJ&hl=en), [Ludwig Schmidt](https://scholar.google.com/citations?user=SWMKy70AAAAJ&hl=en), [Anca D. Dragan](https://scholar.google.com/citations?user=UgHB5oAAAAAJ&hl=en), and [Moritz Hardt](https://scholar.google.com/citations?user=adnTgaAAAAAJ&hl=en). "**Model reconstruction from model explanations**." In Proceedings of the Conference on Fairness, Accountability, and Transparency, 2019. [[**paper**](https://arxiv.org/pdf/1807.05185)] [[**conference talk**](https://youtu.be/iZM4_YNw4Mw?t=593)] [[**citations**](https://scholar.google.com/scholar?cites=10127227002337427345&as_sdt=2005&sciodt=0,5&hl=en)]

### Analysis 

- [Jon Kleinberg](https://scholar.google.com.sg/citations?user=VX7d5EQAAAAJ&hl=en), and [Sendhil Mullainathan](https://scholar.google.com/citations?user=oExfyEkAAAAJ&hl=en). "**Simplicity creates inequity: implications for fairness, stereotypes, and interpretability**." In Proceedings of the 2019 ACM Conference on Economics and Computation, 2019. [[**paper**](https://arxiv.org/pdf/1809.04578)] [[**conference talk**](https://www.youtube.com/watch?v=LsracoT6zvI)] [[**citations**](https://scholar.google.com/scholar?client=firefox-b-d&um=1&ie=UTF-8&lr&cites=4367467261022093783)]

### Law and Policy

- [Andrew D. Selbst](https://scholar.google.com.sg/citations?user=stza7JMAAAAJ&hl=en), and [Solon Barocas](https://scholar.google.com.sg/citations?user=rEjgIskAAAAJ&hl=en). "**The Intuitive Appeal of Explainable Machines**." Fordham law review 87, no. 3, 2018. [[**paper**](http://fordhamlawreview.org/wp-content/uploads/2018/11/11_Selbst-Barocas-1085-1139-updated-12-4.pdf)] 

### Related Courses and Schools

- [Interpretability and Explainability in Machine Learning](https://interpretable-ml-class.github.io/), [Himabindu Lakkaraju](https://scholar.google.com/citations?user=oWid5PQAAAAJ&hl=en), Harvard, 2019.


